{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from hyperparams import Hyperparams as hp\n",
    "import os\n",
    "import codecs\n",
    "from jamo import h2j, j2hcj\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trascript = hp.transcript_pos\n",
    "lines = codecs.open(trascript, 'r', 'utf-8').readlines()\n",
    "\n",
    "if not (os.path.isdir(hp.mels_dir)):\n",
    "    os.mkdir(hp.mels_dir)\n",
    "    print('{%s} does not exist, created {%s}'.format(hp.mels_dir, hp.mels_dir))\n",
    "    \n",
    "if not (os.path.isdir(hp.mags_dir)):\n",
    "    os.mkdir(hp.mags_dir)\n",
    "    print('{%s} does not exist, created {%s}'.format(hp.mags_dir, hp.mags_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocab():\n",
    "    char2idx = {char: idx for idx, char in enumerate(hp.vocab)}\n",
    "    idx2char = {idx: char for idx, char in enumerate(hp.vocab)}\n",
    "    return char2idx, idx2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames, texts, secs, text_lengths = [], [], [], []\n",
    "char2idx, idx2char = load_vocab();\n",
    "\n",
    "for line in tqdm(lines):\n",
    "    line = j2hcj(line)\n",
    "    fname, _, text, sec = line.strip().split('|')\n",
    "    encodedText = [char2idx[char] for char in text]\n",
    "    encodedText = np.array(encodedText, np.int32)#.tostring()\n",
    "    fnames.append(fname); texts.append(encodedText)\n",
    "    secs.append(float(sec)); text_lengths.append(len(encodedText))\n",
    "    \n",
    "fnames = np.asarray(fnames)\n",
    "texts = np.asarray(texts)\n",
    "secs = np.asarray(secs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Selection\n",
    "randIdx = np.random.choice(range(len(lines)), 20)\n",
    "randIdx.sort()\n",
    "print(randIdx)\n",
    "\n",
    "fnames = fnames[randIdx]\n",
    "texts = texts[randIdx]\n",
    "secs = secs[randIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLen, minLen = max(text_lengths), min(text_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram(wav, nsc, nov, fs):\n",
    "    \n",
    "    \n",
    "    S = librosa.feature.melspectrogram(y=wav, sr=fs, n_fft=nsc, hop_length=nov, power=2.0)\n",
    "    dbS = 20 * np.log10(np.maximum(S, hp.eps))\n",
    "    \n",
    "    \n",
    "    return dbS\n",
    "\n",
    "def mel_spectrogram(wav, nsc, nov, fs):\n",
    "    \n",
    "    \n",
    "    S = librosa.feature.melspectrogram(y=wav, sr=fs, n_fft=nsc, hop_length=nov, power=2.0, n_mels = hp.n_mels)\n",
    "    dbS = 20 * np.log10(np.maximum(S, hp.eps))\n",
    "    \n",
    "    \n",
    "    return dbS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(0, len(fnames))):\n",
    "    fname = fnames[i]\n",
    "    text = texts[i]\n",
    "    \n",
    "    npy_name = fname.split('/')[1].replace('wav', 'npy')\n",
    "    mel_path = os.path.join(hp.mels_dir, npy_name)\n",
    "    mag_path = os.path.join(hp.mags_dir, npy_name)\n",
    "    \n",
    "#     if os.path.isfile(mel_path) and os.path.isfile(mag_path):\n",
    "    if False:\n",
    "        \n",
    "        mag = np.load(mag_path)\n",
    "        mel = np.load(mel_path) \n",
    "        \n",
    "    else :\n",
    "    \n",
    "        fpath = os.path.join(hp.data_dir, fname)\n",
    "        wav, fs = librosa.core.load(fpath, mono=True)\n",
    "        nsc = np.int(fs * hp.nsc_sec)\n",
    "        nov = np.int(fs * hp.nov_sec)\n",
    "        mag = spectrogram(wav, nsc, nov, fs)\n",
    "        mel = mel_spectrogram(wav, nsc, nov, fs)\n",
    "        mag_coef = np.mean(mag, axis=0)\n",
    "        \n",
    "        active = np.where(mag_coef > hp.db_limit)[0]\n",
    "        \n",
    "        first = active[0]\n",
    "        last = active[-1] + 1\n",
    "        \n",
    "        if first - hp.offset >= 0:\n",
    "            first = first - hp.offset\n",
    "        else:\n",
    "                first = 0\n",
    "            \n",
    "        if last + hp.offset < len(mag_coef):\n",
    "            last = last + hp.offset\n",
    "        else:\n",
    "            last = len(mag_coef)\n",
    "            \n",
    "        mag = mag[:, first:last]\n",
    "        mel = mel[:, first:last]\n",
    "        \n",
    "        mag = mag / hp.max_db\n",
    "        mel = mel / hp.max_db\n",
    "        \n",
    "        print('{:d}:{:d}'.format(first, last))\n",
    "        \n",
    "        np.save(mag_path, mag)\n",
    "        np.save(mel_path, mel)\n",
    "    \n",
    "    print(fname)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(mag, origin='lower')\n",
    "    plt.colorbar()\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(mel, origin='lower')\n",
    "    plt.colorbar()\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(mag_coef)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"embedding\", reuse=tf.AUTO_REUSE):\n",
    "    lookup_table = tf.get_variable('lookup_table', \n",
    "                                   dtype=tf.float32, \n",
    "                                   shape=[len(hp.vocab), hp.embed_size],\n",
    "                                   initializer=tf.truncated_normal_initializer(mean=0.0, stddev=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(lookup_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_texts = []\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    text = texts[i]\n",
    "    embed_text = tf.nn.embedding_lookup(lookup_table, text)\n",
    "    embed_text = tf.expand_dims(embed_text, 0)\n",
    "    embed_texts.append(embed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_table.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sess.run(embed_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[5][0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prenet_results = []\n",
    "\n",
    "for i in tqdm(range(len(embed_texts))):\n",
    "    embed_text = embed_texts[i]\n",
    "    with tf.variable_scope(\"prenet\", reuse=tf.AUTO_REUSE):\n",
    "        outputs = tf.layers.dense(embed_text, units=hp.num_prenet_node_1, activation=tf.nn.relu, name=\"dense1\")\n",
    "        outputs = tf.layers.dropout(outputs, rate=hp.dropout_rate, name=\"dropout1\")\n",
    "        outputs = tf.layers.dense(outputs, units=hp.num_prenet_node_2, activation=tf.nn.relu, name=\"dense2\")\n",
    "        outputs = tf.layers.dropout(outputs, rate=hp.dropout_rate, name=\"dropout2\") \n",
    "        \n",
    "    prenet_results.append(outputs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess.run(tf.global_variables_initializer())\n",
    "# x = sess.run(prenet_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in tqdm(range(len(embed_texts))):\n",
    "conv_bank_results = []\n",
    "\n",
    "for i in tqdm(range(len(prenet_results))):\n",
    "    with tf.variable_scope(\"conv1d_banks\", reuse=tf.AUTO_REUSE):\n",
    "        prenet_result = prenet_results[i]\n",
    "\n",
    "        for k in range(1, hp.K + 1):\n",
    "            with tf.variable_scope(\"filter_num_{}\".format(k)):\n",
    "                params = {\"inputs\":prenet_result, \"filters\":hp.num_k_filter, \"kernel_size\":k,\n",
    "                        \"dilation_rate\":1, \"padding\":\"SAME\", \"activation\":None, \n",
    "                        \"use_bias\":False, \"reuse\":tf.AUTO_REUSE}\n",
    "                \n",
    "                # Works when resue = True\n",
    "                # For i loop, filter is reused.\n",
    "\n",
    "                conv_outputs = tf.layers.conv1d(**params)\n",
    "                if k == 1:\n",
    "                    conv_bank_outputs = conv_outputs\n",
    "                else:\n",
    "                    conv_bank_outputs = tf.concat((conv_bank_outputs, conv_outputs), axis=2)\n",
    "                \n",
    "    conv_bank_results.append(conv_bank_outputs)\n",
    "                \n",
    "#     print(prenet_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(conv_bank_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
