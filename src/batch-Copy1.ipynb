{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from hyperparams import Hyperparams as hp\n",
    "import os\n",
    "import codecs\n",
    "from jamo import h2j, j2hcj\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trascript = hp.transcript_pos\n",
    "lines = codecs.open(trascript, 'r', 'utf-8').readlines()\n",
    "\n",
    "if not (os.path.isdir(hp.mels_dir)):\n",
    "    os.mkdir(hp.mels_dir)\n",
    "    print('{%s} does not exist, created {%s}'.format(hp.mels_dir, hp.mels_dir))\n",
    "    \n",
    "if not (os.path.isdir(hp.mags_dir)):\n",
    "    os.mkdir(hp.mags_dir)\n",
    "    print('{%s} does not exist, created {%s}'.format(hp.mags_dir, hp.mags_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocab():\n",
    "    char2idx = {char: idx for idx, char in enumerate(hp.vocab)}\n",
    "    idx2char = {idx: char for idx, char in enumerate(hp.vocab)}\n",
    "    return char2idx, idx2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 12853/12853 [00:01<00:00, 11344.51it/s]\n"
     ]
    }
   ],
   "source": [
    "fnames, texts, secs, text_lengths = [], [], [], []\n",
    "\n",
    "for line in tqdm(lines):\n",
    "    line = j2hcj(line)\n",
    "    _, _, text, _ = line.strip().split('|')\n",
    "    text_lengths.append(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen, minLen = max(text_lengths), min(text_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 12853/12853 [00:01<00:00, 9525.04it/s]\n"
     ]
    }
   ],
   "source": [
    "maxlen = max(text_lengths)\n",
    "\n",
    "char2idx, idx2char = load_vocab();\n",
    "\n",
    "for line in tqdm(lines):\n",
    "    line = j2hcj(line)\n",
    "    fname, _, text, sec = line.strip().split('|')\n",
    "    \n",
    "    padLen = maxlen - len(text)\n",
    "    \n",
    "    text = text + ' ' * padLen\n",
    "    \n",
    "    encodedText = [char2idx[char] for char in text]\n",
    "    \n",
    "    encodedText = np.array(encodedText, np.int32).tostring()\n",
    "    \n",
    "    fnames.append(fname); \n",
    "    texts.append(encodedText)\n",
    "    secs.append(float(sec)); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = list(map(lambda x: len(x), texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x262b5d56ef0>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames_tensor = tf.convert_to_tensor(fnames)\n",
    "texts_tensor = tf.convert_to_tensor(texts)\n",
    "lengths_tensor = tf.convert_to_tensor(text_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "dataset = tf.data.Dataset.from_tensor_slices(tuple([fnames_tensor, texts_tensor, lengths_tensor])).shuffle(fnames_tensor.shape[0]).repeat(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_length_fn(fname, text, text_length, c): #(uttids, tgt_ids, tgt_labels, tgt_paddings, frames, src_paddings):\n",
    "#     print(fname)\n",
    "#     print(text)\n",
    "#     print(text_length)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram(wav, nsc, nov, fs):\n",
    "    \n",
    "    \n",
    "    S = librosa.feature.melspectrogram(y=wav, sr=fs, n_fft=nsc, hop_length=nov, power=2.0)\n",
    "    dbS = 20 * np.log10(np.maximum(S, hp.eps))\n",
    "    \n",
    "    \n",
    "    return dbS\n",
    "\n",
    "def mel_spectrogram(wav, nsc, nov, fs):\n",
    "    \n",
    "    \n",
    "    S = librosa.feature.melspectrogram(y=wav, sr=fs, n_fft=nsc, hop_length=nov, power=2.0, n_mels = hp.n_mels)\n",
    "    dbS = 20 * np.log10(np.maximum(S, hp.eps))\n",
    "    \n",
    "    \n",
    "    return dbS\n",
    "\n",
    "def true_spectrogram(wav, nsc, nov):\n",
    "    \n",
    "    \n",
    "    S = librosa.core.stft(wav, n_fft=nsc, hop_length=nov)\n",
    "    Sxx = abs(S)\n",
    "    dbS = 20 * np.log10(np.maximum(Sxx, hp.eps))\n",
    "    \n",
    "    \n",
    "    return dbS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram_wrap_up_(fname, length):\n",
    "    \n",
    "    fname = fname.decode()\n",
    "    npy_name = fname.split('/')[1].replace('wav', 'npy')\n",
    "    mel_path = os.path.join(hp.mels_dir, npy_name)\n",
    "    mag_path = os.path.join(hp.mags_dir, npy_name)\n",
    "\n",
    "    if False:\n",
    "\n",
    "        mag = np.load(mag_path)\n",
    "        mel = np.load(mel_path) \n",
    "\n",
    "    else :\n",
    "\n",
    "        fpath = os.path.join(hp.data_dir, fname)\n",
    "        wav, fs = librosa.core.load(fpath, mono=True)\n",
    "        nsc = np.int(fs * hp.nsc_sec)\n",
    "        nov = np.int(fs * hp.nov_sec)\n",
    "        mag_coef = np.mean(spectrogram(wav, nsc, nov, fs), axis=0)\n",
    "        mel = mel_spectrogram(wav, nsc, nov, fs)\n",
    "        mag = true_spectrogram(wav, nsc, nov)\n",
    "\n",
    "        active = np.where(mag_coef > hp.db_limit)[0]\n",
    "\n",
    "        first = active[0]\n",
    "        last = active[-1] + 1\n",
    "\n",
    "        if first - hp.offset >= 0:\n",
    "            first = first - hp.offset\n",
    "        else:\n",
    "                first = 0\n",
    "\n",
    "        if last + hp.offset < len(mag_coef):\n",
    "            last = last + hp.offset\n",
    "        else:\n",
    "            last = len(mag_coef)\n",
    "\n",
    "        mag = mag[:, first:last]\n",
    "        mel = mel[:, first:last]\n",
    "\n",
    "        mag = mag / hp.max_db\n",
    "        mel = mel / hp.max_db\n",
    "\n",
    "        # Do I really need \n",
    "        t = mel.shape[1]\n",
    "        num_paddings = hp.r - (t % hp.r) if t % hp.r != 0 else 0 # 0 for multiples\n",
    "\n",
    "        mel = np.pad(mel.T, [[0, num_paddings], [0, 0]], mode=\"minimum\")\n",
    "        mag = np.pad(mag.T, [[0, num_paddings], [0, 0]], mode=\"minimum\")\n",
    "\n",
    "        mel = mel.T\n",
    "        mag = mag.T\n",
    "\n",
    "        mel = mel.astype(np.float32)\n",
    "        mag = mag.astype(np.float32) # Default is float64, type crashes at the Attention Wrapper\n",
    "\n",
    "        print('{:d}:{:d}'.format(first, last))\n",
    "\n",
    "        np.save(mag_path, mag)\n",
    "        np.save(mel_path, mel)\n",
    "\n",
    "    y = mel.T.reshape((-1, hp.n_mels*hp.r))\n",
    "    mel = (mel.T[hp.r - 1::hp.r, :]) # Reduce sample size by r\n",
    "    mag = mag.T\n",
    "    \n",
    "#     text.set_shape((None,))\n",
    "    y.set_shape((None, hp.n_mels*hp.r))\n",
    "#     mag.set_shape((None, hp.n_fft//2+1))\n",
    "    \n",
    "#   return y, mel, mag, length\n",
    "    return y, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _resize_function(image_decoded, label):\n",
    "\n",
    "    image_decoded.set_shape([None, None, None])\n",
    "\n",
    "    image_resized = tf.image.resize_images(image_decoded, [28, 28])\n",
    "\n",
    "    return image_resized, label\n",
    "\n",
    "filenames = [\"/var/data/image1.jpg\", \"/var/data/image2.jpg\", ...]\n",
    "\n",
    "labels = [0, 37, 29, 1, ...]\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "\n",
    "dataset = dataset.map(\n",
    "\n",
    "    lambda filename, label: tuple(tf.py_func(\n",
    "\n",
    "        _read_py_function, [filename, label], [tf.uint8, label.dtype])))\n",
    "\n",
    "dataset = dataset.map(_resize_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_help(fnames_tensor, texts_tensor, lengths_tensor):\n",
    "    \n",
    "    print(fnames_tensor)\n",
    "    print(texts_tensor)\n",
    "    print(lengths_tensor)\n",
    "    \n",
    "    [y, length] = spectrogram_wrap_up_(fnames_tensor, lengths_tensor)\n",
    "    \n",
    "    return fnames_tensor, texts_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"arg0:0\", shape=(), dtype=string)\n",
      "Tensor(\"arg1:0\", shape=(), dtype=string)\n",
      "Tensor(\"arg2:0\", shape=(), dtype=int32)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-31f2603cc0a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_help\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[0;32m   1036\u001b[0m     \"\"\"\n\u001b[0;32m   1037\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1038\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1039\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mParallelMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func, use_inter_op_parallelism)\u001b[0m\n\u001b[0;32m   2609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2610\u001b[0m     wrapped_func = StructuredFunctionWrapper(\n\u001b[1;32m-> 2611\u001b[1;33m         map_func, \"Dataset.map()\", input_dataset)\n\u001b[0m\u001b[0;32m   2612\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2613\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_shapes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, add_to_graph, experimental_nested_dataset_support)\u001b[0m\n\u001b[0;32m   1858\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_data_structured_function_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1859\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1860\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1861\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1862\u001b[0m       \u001b[1;31m# Use the private method that will execute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\u001b[0m in \u001b[0;36madd_to_graph\u001b[1;34m(self, g)\u001b[0m\n\u001b[0;32m    477\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m     \u001b[1;34m\"\"\"Adds this function into the graph g.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 479\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_definition_if_needed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Adds this function into 'g'.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\u001b[0m in \u001b[0;36m_create_definition_if_needed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[1;34m\"\"\"Creates the function definition if it's not created yet.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_definition_if_needed_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_create_definition_if_needed_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\u001b[0m in \u001b[0;36m_create_definition_if_needed_impl\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    342\u001b[0m     temp_graph = func_graph_from_py_func(\n\u001b[0;32m    343\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_arg_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_arg_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m         self._capture_by_value, self._caller_device)\n\u001b[0m\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extra_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextra_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(func, arg_names, arg_types, name, capture_by_value, device, colocation_stack, container, collections_ref, arg_shapes)\u001b[0m\n\u001b[0;32m    862\u001b[0m     \u001b[1;31m# Call func and gather the output tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 864\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m     \u001b[1;31m# There is no way of distinguishing between a function not returning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mtf_data_structured_function_wrapper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   1792\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1794\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1795\u001b[0m       \u001b[1;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1796\u001b[0m       \u001b[1;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-74-86903bca5120>\u001b[0m in \u001b[0;36mfunc_help\u001b[1;34m(fnames_tensor, texts_tensor, lengths_tensor)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspectrogram_wrap_up_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfnames_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlengths_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfnames_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtexts_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-57-8dcd7e6559b2>\u001b[0m in \u001b[0;36mspectrogram_wrap_up_\u001b[1;34m(fname, length)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mspectrogram_wrap_up_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mnpy_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'wav'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmel_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmels_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnpy_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "dataset3 = dataset.map(func_help)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((), ()), types: (tf.string, tf.string)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = dataset.map(\n",
    "    lambda fname, text, lengths: tf.py_func(spectrogram_wrap_up_,\n",
    "                                [fname, lengths],\n",
    "                                [tf.float32, tf.int32]))\n",
    "\n",
    "# dataset2 = dataset.map(\n",
    "#     lambda fname, text, lengths: tf.py_func(spectrogram_wrap_up_,\n",
    "#                                 [fname, lengths],\n",
    "#                                 [tf.float32, tf.float32, tf.float32, tf.int32]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'RepeatDataset' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-65b2316a173e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_from_datasets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\interleave_ops.py\u001b[0m in \u001b[0;36msample_from_datasets\u001b[1;34m(datasets, weights, seed)\u001b[0m\n\u001b[0;32m    158\u001b[0m       \u001b[0mlength\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m   \"\"\"\n\u001b[1;32m--> 160\u001b[1;33m   \u001b[0mnum_datasets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'RepeatDataset' has no len()"
     ]
    }
   ],
   "source": [
    "tf.data.experimental.sample_from_datasets(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "batch_dataset = dataset2.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = batch_dataset.make_one_shot_iterator()\n",
    "# y, mel, mag, length = iterator.get_next()\n",
    "y, length = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:109\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "AttributeError: 'numpy.ndarray' object has no attribute 'set_shape'\nTraceback (most recent call last):\n\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 206, in __call__\n    ret = func(*args)\n\n  File \"<ipython-input-57-8dcd7e6559b2>\", line 67, in spectrogram_wrap_up_\n    y.set_shape((None, hp.n_mels*hp.r))\n\nAttributeError: 'numpy.ndarray' object has no attribute 'set_shape'\n\n\n\t [[{{node PyFunc}} = PyFunc[Tin=[DT_STRING, DT_INT32], Tout=[DT_FLOAT, DT_INT32], token=\"pyfunc_8\"](arg0, arg2)]]\n\t [[node IteratorGetNext_6 (defined at <ipython-input-63-8431d85a715f>:3)  = IteratorGetNext[output_shapes=[<unknown>, <unknown>], output_types=[DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_6)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: AttributeError: 'numpy.ndarray' object has no attribute 'set_shape'\nTraceback (most recent call last):\n\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 206, in __call__\n    ret = func(*args)\n\n  File \"<ipython-input-57-8dcd7e6559b2>\", line 67, in spectrogram_wrap_up_\n    y.set_shape((None, hp.n_mels*hp.r))\n\nAttributeError: 'numpy.ndarray' object has no attribute 'set_shape'\n\n\n\t [[{{node PyFunc}} = PyFunc[Tin=[DT_STRING, DT_INT32], Tout=[DT_FLOAT, DT_INT32], token=\"pyfunc_8\"](arg0, arg2)]]\n\t [[{{node IteratorGetNext_6}} = IteratorGetNext[output_shapes=[<unknown>, <unknown>], output_types=[DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_6)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-af0404d468fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0my_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlengths_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: AttributeError: 'numpy.ndarray' object has no attribute 'set_shape'\nTraceback (most recent call last):\n\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 206, in __call__\n    ret = func(*args)\n\n  File \"<ipython-input-57-8dcd7e6559b2>\", line 67, in spectrogram_wrap_up_\n    y.set_shape((None, hp.n_mels*hp.r))\n\nAttributeError: 'numpy.ndarray' object has no attribute 'set_shape'\n\n\n\t [[{{node PyFunc}} = PyFunc[Tin=[DT_STRING, DT_INT32], Tout=[DT_FLOAT, DT_INT32], token=\"pyfunc_8\"](arg0, arg2)]]\n\t [[node IteratorGetNext_6 (defined at <ipython-input-63-8431d85a715f>:3)  = IteratorGetNext[output_shapes=[<unknown>, <unknown>], output_types=[DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_6)]]"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:    \n",
    "    for i in range(3):\n",
    "        y_, lengths_ = sess.run([y, length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:73\n",
      "8:39\n",
      "13:81\n",
      "10:78\n",
      "0:51\n",
      "12:49\n",
      "12:100\n",
      "17:50\n",
      "18:52\n",
      "15:51\n",
      "15:79\n",
      "9:48\n",
      "10:49\n",
      "3:45\n",
      "18:68\n",
      "13:56\n",
      "7:57\n",
      "17:78\n",
      "7:63\n",
      "11:66\n",
      "10:49\n",
      "15:86\n",
      "5:63\n",
      "7:80\n",
      "13:74\n",
      "15:101\n",
      "14:112\n",
      "10:47\n",
      "14:72\n",
      "7:41\n",
      "20:74\n",
      "6:40\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot batch tensors with different shapes in component 0. First element had shape [12,400] and element 1 had shape [7,400].\n\t [[node IteratorGetNext_3 (defined at <ipython-input-47-825243917d57>:2)  = IteratorGetNext[output_shapes=[<unknown>, <unknown>, <unknown>, <unknown>], output_types=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_3)]]\n\nCaused by op 'IteratorGetNext_3', defined at:\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\asyncio\\base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\asyncio\\base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-47-825243917d57>\", line 2, in <module>\n    y, mel, mag, length = iterator.get_next()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 421, in get_next\n    name=name)), self._output_types,\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 2108, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot batch tensors with different shapes in component 0. First element had shape [12,400] and element 1 had shape [7,400].\n\t [[node IteratorGetNext_3 (defined at <ipython-input-47-825243917d57>:2)  = IteratorGetNext[output_shapes=[<unknown>, <unknown>, <unknown>, <unknown>], output_types=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_3)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Cannot batch tensors with different shapes in component 0. First element had shape [12,400] and element 1 had shape [7,400].\n\t [[{{node IteratorGetNext_3}} = IteratorGetNext[output_shapes=[<unknown>, <unknown>, <unknown>, <unknown>], output_types=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_3)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-115e0b6d954b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0my_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmel_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmag_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlengths_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#       print(mel_)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Cannot batch tensors with different shapes in component 0. First element had shape [12,400] and element 1 had shape [7,400].\n\t [[node IteratorGetNext_3 (defined at <ipython-input-47-825243917d57>:2)  = IteratorGetNext[output_shapes=[<unknown>, <unknown>, <unknown>, <unknown>], output_types=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_3)]]\n\nCaused by op 'IteratorGetNext_3', defined at:\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\asyncio\\base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\asyncio\\base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-47-825243917d57>\", line 2, in <module>\n    y, mel, mag, length = iterator.get_next()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 421, in get_next\n    name=name)), self._output_types,\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 2108, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot batch tensors with different shapes in component 0. First element had shape [12,400] and element 1 had shape [7,400].\n\t [[node IteratorGetNext_3 (defined at <ipython-input-47-825243917d57>:2)  = IteratorGetNext[output_shapes=[<unknown>, <unknown>, <unknown>, <unknown>], output_types=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_3)]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:    \n",
    "    for i in range(3):\n",
    "        y_, mel_, mag_, lengths_ = sess.run([y, mel, mag, length])\n",
    "#       print(mel_)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(mel_.T, origin='lower')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(mag_.T, origin='lower')\n",
    "        plt.show()\n",
    "        print(lengths_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "batch_dataset = dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.apply(\n",
    "                        tf.data.experimental.bucket_by_sequence_length(\n",
    "                        element_length_func=dataset_length_fn,\n",
    "                        bucket_batch_sizes= [32, 32, 32, 32, 32, 32, 32, 32],\n",
    "                        bucket_boundaries=[10, 20, 30, 40, 50, 60, 70],\n",
    "#                         pad_to_bucket_boundary = [False, True, False]\n",
    "                        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = batch_dataset.make_one_shot_iterator()\n",
    "y, mel, mag = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:    \n",
    "    for i in range(3):\n",
    "        y_, mel_, mag_ = sess.run([y, mel, mag])\n",
    "#       print(mel_)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(mel_.T, origin='lower')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(mag_.T, origin='lower')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, mel, mag = tf.py_func(spectrogram_wrap_up_, [dataset], [tf.float32, tf.float32, tf.float32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:    \n",
    "    for i in range(30):\n",
    "        a, b, c = sess.run([file_name, text, length], feed_dict={fnames_placeholder: fnames, \n",
    "                                              texts_placeholder: texts, \n",
    "                                              lengths_placeholder: text_lengths\n",
    "                                                                })\n",
    "        print(a)\n",
    "        print(b)\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "batch_dataset = dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset.make_one_shot_iterator()`\n",
    "file_name, text = iterator.get_next()\n",
    "text_decoded = tf.decode_raw(text, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, mel, mag = tf.py_func(spectrogram_wrap_up, [fname], [tf.float32, tf.float32, tf.float32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.experimental.bucket_by_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.experimental.bucket_by_sequence_length(\n",
    "    element_length_func,\n",
    "    bucket_boundaries,\n",
    "    bucket_batch_sizes,\n",
    "    padded_shapes=None,\n",
    "    pad_to_bucket_boundary=False,\n",
    "    no_padding=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterator = dataset.make_one_shot_iterator()\n",
    "# file_name, text = iterator.get_next()\n",
    "# text_decoded = tf.decode_raw(text, tf.int32)\n",
    "\n",
    "iterator = batch_dataset.make_one_shot_iterator()\n",
    "file_name, text = iterator.get_next()\n",
    "text_decoded = tf.decode_raw(text, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:    \n",
    "    for i in range(3):\n",
    "        f, t = sess.run([file_name, text])\n",
    "        print(f)\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:    \n",
    "    for i in range(3):\n",
    "        f, t = sess.run([file_name, text_decoded])\n",
    "        print(f)\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_decay(init_lr, global_step, warmup_steps=4000.):\n",
    "    '''Noam scheme from tensor2tensor'''\n",
    "    step = tf.cast(global_step + 1, dtype=tf.float32)\n",
    "    return init_lr * warmup_steps ** 0.5 * tf.minimum(step * warmup_steps ** -1.5, step ** -0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = file_name\n",
    "text = text_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram_wrap_up(fname):\n",
    "    \n",
    "    fname = fname.decode()\n",
    "    npy_name = fname.split('/')[1].replace('wav', 'npy')\n",
    "    mel_path = os.path.join(hp.mels_dir, npy_name)\n",
    "    mag_path = os.path.join(hp.mags_dir, npy_name)\n",
    "    \n",
    "    #     if os.path.isfile(mel_path) and os.path.isfile(mag_path):\n",
    "    if False:\n",
    "\n",
    "        mag = np.load(mag_path)\n",
    "        mel = np.load(mel_path) \n",
    "\n",
    "    else :\n",
    "\n",
    "        fpath = os.path.join(hp.data_dir, fname)\n",
    "        wav, fs = librosa.core.load(fpath, mono=True)\n",
    "        nsc = np.int(fs * hp.nsc_sec)\n",
    "        nov = np.int(fs * hp.nov_sec)\n",
    "        mag_coef = np.mean(spectrogram(wav, nsc, nov, fs), axis=0)\n",
    "        mel = mel_spectrogram(wav, nsc, nov, fs)\n",
    "        mag = true_spectrogram(wav, nsc, nov)\n",
    "\n",
    "        active = np.where(mag_coef > hp.db_limit)[0]\n",
    "\n",
    "        first = active[0]\n",
    "        last = active[-1] + 1\n",
    "\n",
    "        if first - hp.offset >= 0:\n",
    "            first = first - hp.offset\n",
    "        else:\n",
    "                first = 0\n",
    "\n",
    "        if last + hp.offset < len(mag_coef):\n",
    "            last = last + hp.offset\n",
    "        else:\n",
    "            last = len(mag_coef)\n",
    "\n",
    "        mag = mag[:, first:last]\n",
    "        mel = mel[:, first:last]\n",
    "\n",
    "        mag = mag / hp.max_db\n",
    "        mel = mel / hp.max_db\n",
    "\n",
    "        # Do I really need \n",
    "        t = mel.shape[1]\n",
    "        num_paddings = hp.r - (t % hp.r) if t % hp.r != 0 else 0 # 0 for multiples\n",
    "\n",
    "        mel = np.pad(mel.T, [[0, num_paddings], [0, 0]], mode=\"minimum\")\n",
    "        mag = np.pad(mag.T, [[0, num_paddings], [0, 0]], mode=\"minimum\")\n",
    "\n",
    "        mel = mel.T\n",
    "        mag = mag.T\n",
    "\n",
    "        mel = mel.astype(np.float32)\n",
    "        mag = mag.astype(np.float32) # Default is float64, type crashes at the Attention Wrapper\n",
    "\n",
    "        print('{:d}:{:d}'.format(first, last))\n",
    "\n",
    "        np.save(mag_path, mag)\n",
    "        np.save(mel_path, mel)\n",
    "\n",
    "#     print(fname)\n",
    "#     plt.figure(figsize=(20, 4))\n",
    "#     plt.subplot(1, 3, 1)\n",
    "#     plt.imshow(mag, origin='lower')\n",
    "#     plt.colorbar()\n",
    "#     plt.subplot(1, 3, 2)\n",
    "#     plt.imshow(mel, origin='lower')\n",
    "#     plt.colorbar()\n",
    "#     plt.subplot(1, 3, 3)\n",
    "#     plt.plot(mag_coef)\n",
    "#     plt.show()\n",
    "\n",
    "    y = mel.T.reshape((-1, hp.n_mels*hp.r))\n",
    "    mel = (mel.T[hp.r - 1::hp.r, :]) # Reduce sample size by r\n",
    "    mag = mag.T\n",
    "    \n",
    "    return y, mel, mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram_wrap_up_2(names):\n",
    "    \n",
    "    y = []\n",
    "    mel = []\n",
    "    mag = []\n",
    "    \n",
    "    for name in names:\n",
    "#       print(name)\n",
    "        y_, mel_, mag_ = spectrogram_wrap_up(name)\n",
    "        y.append(y_)\n",
    "        mel.append(mel_)\n",
    "        mag.append(mag_)\n",
    "        \n",
    "    y = np.asarray(y)\n",
    "    mel = np.asarray(mel)\n",
    "    mag = np.asarray(mag)\n",
    "    \n",
    "    return y, mel, mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y, mel, mag = tf.py_func(spectrogram_wrap_up, [fname], [tf.float32, tf.float32, tf.float32])\n",
    "y, mel, mag = tf.py_func(spectrogram_wrap_up_2, [fname], [tf.float32, tf.float32, tf.float32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:    \n",
    "    for i in range(3):\n",
    "        f = sess.run([fname])\n",
    "        print(f[0][0].decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:    \n",
    "    for i in range(3):\n",
    "        y_, mel_, mag_ = sess.run([y, mel, mag])\n",
    "        print(mel_)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(mel_[0].T, origin='lower')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(mag_[0].T, origin='lower')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = tf.concat((tf.zeros_like(mel[:1, :]), mel[:-1, :]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input.set_shape([None, hp.n_mels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"embedding\", reuse=tf.AUTO_REUSE):\n",
    "    lookup_table = tf.get_variable('lookup_table', \n",
    "                                   dtype=tf.float32, \n",
    "                                   shape=[len(hp.vocab), hp.embed_size],\n",
    "                                   initializer=tf.truncated_normal_initializer(mean=0.0, stddev=0.01))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_text = tf.nn.embedding_lookup(lookup_table, text_decoded)\n",
    "embed_text = tf.expand_dims(embed_text, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    x = sess.run(embed_text)\n",
    "    plt.imshow(x[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"prenet\", reuse=tf.AUTO_REUSE):\n",
    "    outputs = tf.layers.dense(embed_text, units=hp.num_prenet_node_1, activation=tf.nn.relu, name=\"dense1\")\n",
    "    outputs = tf.layers.dropout(outputs, rate=hp.dropout_rate, name=\"dropout1\")\n",
    "    outputs = tf.layers.dense(outputs, units=hp.num_prenet_node_2, activation=tf.nn.relu, name=\"dense2\")\n",
    "    outputs = tf.layers.dropout(outputs, rate=hp.dropout_rate, name=\"dropout2\") \n",
    "\n",
    "    prenet_result = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    x = sess.run(prenet_result)\n",
    "    plt.imshow(x[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"conv1d_banks\", reuse=tf.AUTO_REUSE):\n",
    "    for k in range(1, hp.K + 1):\n",
    "        with tf.variable_scope(\"filter_num_{}\".format(k)):\n",
    "            params = {\"inputs\":prenet_result, \"filters\":hp.num_k_filter, \"kernel_size\":k,\n",
    "                    \"dilation_rate\":1, \"padding\":\"SAME\", \"activation\":None, \n",
    "                    \"use_bias\":False, \"reuse\":tf.AUTO_REUSE}\n",
    "\n",
    "            # Works when resue = True\n",
    "            # For i loop, filter is reused.\n",
    "\n",
    "            conv_outputs = tf.layers.conv1d(**params)\n",
    "            if k == 1:\n",
    "                conv_bank_outputs = conv_outputs\n",
    "            else:\n",
    "                conv_bank_outputs = tf.concat((conv_bank_outputs, conv_outputs), axis=2)\n",
    "\n",
    "    conv_bank_result = conv_bank_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    x = sess.run(conv_bank_result)\n",
    "    plt.imshow(x[0, :, :], aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " max_pooling_result = tf.layers.max_pooling1d(conv_bank_result, pool_size=2, strides=1, padding=\"same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    x = sess.run(max_pooling_result)\n",
    "    plt.imshow(x[0, :, :], aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_bank_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"conv1d_1\"):       \n",
    "    params = {\"inputs\":max_pooling_result, \"filters\":hp.num_conv1d_proj_filter, \"kernel_size\":hp.size_conv1d_proj_filter,\n",
    "                    \"dilation_rate\":1, \"padding\":\"SAME\", \"activation\":None, \n",
    "                    \"use_bias\":False, \"reuse\":tf.AUTO_REUSE}\n",
    "    conv_proj_1_result = tf.layers.conv1d(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    x = sess.run(conv_proj_1_result)\n",
    "    plt.imshow(x[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"conv1d_1\"):\n",
    "    bn_1_result = tf.contrib.layers.batch_norm(inputs=conv_proj_1_result,\n",
    "                                           center=True,\n",
    "                                           scale=True,\n",
    "                                           updates_collections=None,\n",
    "                                           is_training=True,\n",
    "                                           scope=\"conv1d_1\",\n",
    "                                           fused=True,\n",
    "                                           reuse=tf.AUTO_REUSE)\n",
    "    batch_norm_1_result = tf.nn.relu(bn_1_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    x = sess.run(batch_norm_1_result)\n",
    "    plt.imshow(x[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"conv1d_2\"):\n",
    "    params = {\"inputs\":batch_norm_1_result, \"filters\":hp.num_conv1d_proj_filter, \"kernel_size\":hp.size_conv1d_proj_filter,\n",
    "                    \"dilation_rate\":1, \"padding\":\"SAME\", \"activation\":None, \n",
    "                    \"use_bias\":False, \"reuse\":tf.AUTO_REUSE}\n",
    "    conv_proj_2_result = tf.layers.conv1d(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    x = sess.run(conv_proj_2_result)\n",
    "    plt.imshow(x[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"conv1d_2\"):\n",
    "    bn_2_result = tf.contrib.layers.batch_norm(inputs=conv_proj_2_result,\n",
    "                                           center=True,\n",
    "                                           scale=True,\n",
    "                                           updates_collections=None,\n",
    "                                           is_training=True,\n",
    "                                           scope=\"conv1d_2\",\n",
    "                                           fused=True,\n",
    "                                           reuse=tf.AUTO_REUSE)\n",
    "    batch_norm_2_result = tf.nn.relu(bn_2_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    x = sess.run(batch_norm_2_result)\n",
    "    plt.imshow(x[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_output = prenet_result + batch_norm_2_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    x = sess.run(res_output)\n",
    "    plt.imshow(x[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highwaynet_output = []\n",
    "\n",
    "for i in range(hp.num_highwaynet_blocks):\n",
    "    scope = \"highwaynet_{:d}\".format(i)\n",
    "    with tf.variable_scope(scope):\n",
    "        \n",
    "        if i == 0:\n",
    "            highwaynet_input = res_output\n",
    "        else:\n",
    "            highwaynet_input = highwaynet_output\n",
    "\n",
    "        H = tf.layers.dense(highwaynet_input, units=hp.num_highwaynet_units, activation=tf.nn.relu, name=\"dense1\", reuse=tf.AUTO_REUSE)\n",
    "        T = tf.layers.dense(highwaynet_input, units=hp.num_highwaynet_units, activation=tf.nn.sigmoid,\n",
    "                            bias_initializer=tf.constant_initializer(-1.0), name=\"dense2\", reuse=tf.AUTO_REUSE)\n",
    "        highwaynet_output = H*T + highwaynet_input*(1.-T)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highwaynet_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    x = sess.run(highwaynet_output)\n",
    "    plt.imshow(x[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"gru\", reuse=tf.AUTO_REUSE):\n",
    "#     cell = tf.contrib.rnn.GRUCell(hp.num_gru_units)\n",
    "#     cell_bw = tf.contrib.rnn.GRUCell(hp.num_gru_units)\n",
    "    cell = tf.contrib.rnn.GRUCell(128)\n",
    "    cell_bw = tf.contrib.rnn.GRUCell(128)\n",
    "\n",
    "    output, _ = tf.nn.bidirectional_dynamic_rnn(cell, cell_bw, highwaynet_output, dtype=tf.float32)\n",
    "    gru_result = tf.concat(output, 2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"decoder_prenet\", reuse=tf.AUTO_REUSE):\n",
    "    outputs = tf.layers.dense(decoder_input, units=hp.num_prenet_node_1, activation=tf.nn.relu, name=\"dense1\")\n",
    "    outputs = tf.layers.dropout(outputs, rate=hp.dropout_rate, name=\"dropout1\")\n",
    "    outputs = tf.layers.dense(outputs, units=hp.num_prenet_node_2, activation=tf.nn.relu, name=\"dense2\")\n",
    "    decoder_prenet_result = tf.layers.dropout(outputs, rate=hp.dropout_rate, name=\"dropout2\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_prenet_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    x = sess.run(decoder_prenet_result)\n",
    "    plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_prenet_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_prenet_result_4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"attention_decoder\", reuse=tf.AUTO_REUSE):\n",
    "    \n",
    "    decoder_prenet_result_4D = tf.expand_dims(decoder_prenet_result, 0)\n",
    "\n",
    "    attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(hp.num_attention_units, gru_result)\n",
    "    decoder_cell = tf.contrib.rnn.GRUCell(hp.num_gru_units)\n",
    "    cell_with_attention = tf.contrib.seq2seq.AttentionWrapper(decoder_cell,\n",
    "                                                              attention_mechanism,\n",
    "                                                              hp.num_attention_units,\n",
    "                                                              alignment_history=True)\n",
    "    dec, state = tf.nn.dynamic_rnn(cell_with_attention, decoder_prenet_result_4D, dtype=tf.float32)\n",
    "#     dec, state = keras.layers.RNN(cell_with_attention, decoder_prenet_result_4D, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_prenet_result_4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    x = sess.run(state)\n",
    "    x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"attention_decoder\", reuse=tf.AUTO_REUSE):\n",
    "    \n",
    "    alignment = tf.transpose(state.alignment_history.stack(),[1,2,0])\n",
    "\n",
    "    with tf.variable_scope(\"decoder_gru_1\", reuse=tf.AUTO_REUSE):\n",
    "        cell = tf.contrib.rnn.GRUCell(128)\n",
    "        output, _ = tf.nn.dynamic_rnn(cell, dec, dtype=tf.float32)\n",
    "        gru_output_1 = tf.concat(output, 2)\n",
    "\n",
    "    dec = dec + gru_output_1\n",
    "\n",
    "    with tf.variable_scope(\"decoder_gru_2\", reuse=tf.AUTO_REUSE):\n",
    "        cell = tf.contrib.rnn.GRUCell(128)\n",
    "        output, _ = tf.nn.dynamic_rnn(cell, dec, dtype=tf.float32)\n",
    "        gru_output_2 = tf.concat(output, 2)\n",
    "\n",
    "    dec = dec + gru_output_2\n",
    "\n",
    "    # Outputs => (N, T_y/r, n_mels*r)\n",
    "    y_hat = tf.layers.dense(dec, hp.n_mels*hp.r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    x = sess.run(y_hat)\n",
    "    plt.imshow(x[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"decoder2\", reuse=tf.AUTO_REUSE):\n",
    "    dec_2_input = tf.reshape(y_hat, [1, -1, hp.n_mels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"decoder2\", reuse=tf.AUTO_REUSE):\n",
    "    with tf.variable_scope(\"conv1d_banks\", reuse=tf.AUTO_REUSE):\n",
    "        for k in range(1, hp.K + 1):\n",
    "            with tf.variable_scope(\"filter_num_{}\".format(k)):\n",
    "                params = {\"inputs\":dec_2_input, \"filters\":hp.num_k_filter, \"kernel_size\":k,\n",
    "                        \"dilation_rate\":1, \"padding\":\"SAME\", \"activation\":None, \n",
    "                        \"use_bias\":False, \"reuse\":tf.AUTO_REUSE}\n",
    "\n",
    "                # Works when resue = True\n",
    "                # For i loop, filter is reused.\n",
    "\n",
    "                conv_outputs = tf.layers.conv1d(**params)\n",
    "                if k == 1:\n",
    "                    conv_bank_outputs = conv_outputs\n",
    "                else:\n",
    "                    conv_bank_outputs = tf.concat((conv_bank_outputs, conv_outputs), axis=2)\n",
    "\n",
    "    dec_2_conv_bank_result = conv_bank_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"decoder2\", reuse=tf.AUTO_REUSE):\n",
    "    dec_2_max_pooling_result = tf.layers.max_pooling1d(dec_2_conv_bank_result, pool_size=2, strides=1, padding=\"same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"decoder2\", reuse=tf.AUTO_REUSE):\n",
    "    with tf.variable_scope(\"conv1d_1\"):\n",
    "        params = {\"inputs\":dec_2_max_pooling_result, \"filters\":hp.num_conv1d_proj_filter, \"kernel_size\":hp.size_conv1d_proj_filter,\n",
    "                        \"dilation_rate\":1, \"padding\":\"SAME\", \"activation\":None, \n",
    "                        \"use_bias\":False, \"reuse\":tf.AUTO_REUSE}\n",
    "\n",
    "        dec_2_conv_proj_1_result = tf.layers.conv1d(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"decoder2\", reuse=tf.AUTO_REUSE):\n",
    "    with tf.variable_scope(\"conv1d_1\"):\n",
    "        bn_1_result = tf.contrib.layers.batch_norm(inputs=dec_2_conv_proj_1_result,\n",
    "                                               center=True,\n",
    "                                               scale=True,\n",
    "                                               updates_collections=None,\n",
    "                                               is_training=True,\n",
    "                                               scope=\"conv1d_1\",\n",
    "                                               fused=True,\n",
    "                                               reuse=tf.AUTO_REUSE)\n",
    "        dec_2_batch_norm_1_result = tf.nn.relu(bn_1_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"decoder2\", reuse=tf.AUTO_REUSE):\n",
    "    with tf.variable_scope(\"conv1d_2\"):\n",
    "        params = {\"inputs\":dec_2_batch_norm_1_result, \"filters\":hp.num_conv1d_proj_filter, \"kernel_size\":hp.size_conv1d_proj_filter,\n",
    "                        \"dilation_rate\":1, \"padding\":\"SAME\", \"activation\":None, \n",
    "                        \"use_bias\":False, \"reuse\":tf.AUTO_REUSE}\n",
    "\n",
    "        dec_2_conv_proj_2_result = tf.layers.conv1d(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"decoder2\", reuse=tf.AUTO_REUSE):\n",
    "    with tf.variable_scope(\"conv1d_2\"):\n",
    "        bn_2_result = tf.contrib.layers.batch_norm(inputs=dec_2_conv_proj_2_result,\n",
    "                                               center=True,\n",
    "                                               scale=True,\n",
    "                                               updates_collections=None,\n",
    "                                               is_training=True,\n",
    "                                               scope=\"conv1d_2\",\n",
    "                                               fused=True,\n",
    "                                               reuse=tf.AUTO_REUSE)\n",
    "        dec_2_batch_norm_2_result = tf.nn.relu(bn_2_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"decoder2\", reuse=tf.AUTO_REUSE):\n",
    "    dec_2_sync_result = tf.layers.dense(dec_2_batch_norm_2_result, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"decoder2\", reuse=tf.AUTO_REUSE):\n",
    "    for i in range(hp.num_highwaynet_blocks):\n",
    "        scope = \"highwaynet_{:d}\".format(i)\n",
    "        with tf.variable_scope(scope):\n",
    "\n",
    "            if i == 0:\n",
    "                highwaynet_input = dec_2_sync_result\n",
    "            else:\n",
    "                highwaynet_input = highwaynet_output\n",
    "\n",
    "            highwaynet_output = []\n",
    "\n",
    "            H = tf.layers.dense(highwaynet_input, units=hp.num_highwaynet_units, activation=tf.nn.relu, name=\"dense1\", reuse=tf.AUTO_REUSE)\n",
    "            T = tf.layers.dense(highwaynet_input, units=hp.num_highwaynet_units, activation=tf.nn.sigmoid,\n",
    "                                bias_initializer=tf.constant_initializer(-1.0), name=\"dense2\", reuse=tf.AUTO_REUSE)\n",
    "            highwaynet_output = H*T + highwaynet_input*(1.-T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"dec_2_gru\", reuse=tf.AUTO_REUSE):\n",
    "    cell = tf.contrib.rnn.GRUCell(128)\n",
    "    cell_bw = tf.contrib.rnn.GRUCell(128)\n",
    "\n",
    "    output, _ = tf.nn.bidirectional_dynamic_rnn(cell, cell_bw, highwaynet_output, dtype=tf.float32)\n",
    "    dec_2_gru_result = tf.concat(output, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"decoder2\", reuse=tf.AUTO_REUSE):\n",
    "    with tf.variable_scope(\"final\", reuse=tf.AUTO_REUSE):\n",
    "        z_hat = tf.layers.dense(dec_2_gru_result, 1 + hp.nsc_sec*hp.fs//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 = tf.reduce_mean(tf.abs(y_hat - y))\n",
    "loss2 = tf.reduce_mean(tf.abs(z_hat - mag))\n",
    "loss = loss1 + loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    x = sess.run(loss)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "lr = learning_rate_decay(hp.lr, global_step=global_step)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=hp.lr)\n",
    "\n",
    "## gradient clipping\n",
    "gvs = optimizer.compute_gradients(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped = []\n",
    "\n",
    "for grad, var in gvs:\n",
    "    if grad is None:\n",
    "        clipped.append((grad, var))\n",
    "    else :\n",
    "        grad = tf.clip_by_norm(grad, 5.)\n",
    "        clipped.append((grad, var))\n",
    "    \n",
    "train_op = optimizer.apply_gradients(clipped, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'train'\n",
    "\n",
    "tf.summary.scalar('{}/loss1'.format(mode), loss1)\n",
    "tf.summary.scalar('{}/loss'.format(mode), loss)\n",
    "tf.summary.scalar('{}/lr'.format(mode), hp.lr)\n",
    "\n",
    "tf.summary.image(\"{}/mel_gt\".format(mode), tf.expand_dims(y, -1), max_outputs=1)\n",
    "tf.summary.image(\"{}/mel_hat\".format(mode), tf.expand_dims(y_hat, -1), max_outputs=1)\n",
    "tf.summary.image(\"{}/mag_gt\".format(mode), tf.expand_dims(mag, -1), max_outputs=1)\n",
    "tf.summary.image(\"{}/mag_hat\".format(mode), tf.expand_dims(z_hat, -1), max_outputs=1)\n",
    "\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    for i in range(100):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        _, gs = sess.run([train_op, global_step])\n",
    "        print(gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.logdir = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.train.MonitoredTrainingSession(summary_dir=hp.logdir, save_summaries_secs=60) as sess:\n",
    "    while 1:\n",
    "        for _ in tqdm(range(100), total=100, ncols=70, leave=False, unit='b'):\n",
    "            #_, gs = sess.run([train_op, global_step])\n",
    "            \n",
    "            _, gs = sess.run([dec_2_sync_result])\n",
    "\n",
    "            # Write checkpoint files\n",
    "            if gs % 1000 == 0:\n",
    "                sv.saver.save(sess, hp.logdir + '/model_gs_{}k'.format(gs//1000))\n",
    "\n",
    "                # plot the first alignment for logging\n",
    "                al = sess.run(alignment)\n",
    "                plt.imshow(al[0])\n",
    "                ply.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
