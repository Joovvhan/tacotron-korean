{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from hyperparams import Hyperparams as hp\n",
    "import os\n",
    "import codecs\n",
    "from jamo import h2j, j2hcj\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trascript = hp.transcript_pos\n",
    "lines = codecs.open(trascript, 'r', 'utf-8').readlines()\n",
    "\n",
    "if not (os.path.isdir(hp.mels_dir)):\n",
    "    os.mkdir(hp.mels_dir)\n",
    "    print('{%s} does not exist, created {%s}'.format(hp.mels_dir, hp.mels_dir))\n",
    "    \n",
    "if not (os.path.isdir(hp.mags_dir)):\n",
    "    os.mkdir(hp.mags_dir)\n",
    "    print('{%s} does not exist, created {%s}'.format(hp.mags_dir, hp.mags_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocab():\n",
    "    char2idx = {char: idx for idx, char in enumerate(hp.vocab)}\n",
    "    idx2char = {idx: char for idx, char in enumerate(hp.vocab)}\n",
    "    return char2idx, idx2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 12853/12853 [00:01<00:00, 11758.56it/s]\n"
     ]
    }
   ],
   "source": [
    "fnames, texts, secs, text_lengths = [], [], [], []\n",
    "\n",
    "for line in tqdm(lines):\n",
    "    line = j2hcj(line)\n",
    "    _, _, text, _ = line.strip().split('|')\n",
    "    text_lengths.append(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen, minLen = max(text_lengths), min(text_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 12853/12853 [00:01<00:00, 9997.96it/s]\n"
     ]
    }
   ],
   "source": [
    "maxlen = max(text_lengths)\n",
    "\n",
    "char2idx, idx2char = load_vocab();\n",
    "\n",
    "for line in tqdm(lines):\n",
    "    line = j2hcj(line)\n",
    "    fname, _, text, sec = line.strip().split('|')\n",
    "    \n",
    "    padLen = maxlen - len(text)\n",
    "    \n",
    "    text = text + ' ' * padLen\n",
    "    \n",
    "    encodedText = [char2idx[char] for char in text]\n",
    "    \n",
    "    encodedText = np.array(encodedText, np.int32).tostring()\n",
    "    \n",
    "    fnames.append(fname); \n",
    "    texts.append(encodedText)\n",
    "    secs.append(float(sec)); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = list(map(lambda x: len(x), texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ff109346a0>]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames_tensor = tf.convert_to_tensor(fnames)\n",
    "texts_tensor = tf.convert_to_tensor(texts)\n",
    "lengths_tensor = tf.convert_to_tensor(text_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_15:0' shape=(12853,) dtype=string>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnames_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_16:0' shape=(12853,) dtype=string>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fnames_placeholder = tf.placeholder(fnames_tensor.dtype, [None, ])\n",
    "# texts_placeholder = tf.placeholder(texts_tensor.dtype, [None, ])\n",
    "# lengths_placeholder = tf.placeholder(lengths_tensor.dtype, [None,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "dataset = tf.data.Dataset.from_tensor_slices(tuple([fnames_tensor, texts_tensor, lengths_tensor])).shuffle(fnames_tensor.shape[0]).repeat(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = 1\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((fnames_placeholder, texts_placeholder, lengths_placeholder)).shuffle(fnames_tensor.shape[0]).repeat(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_length_fn(fname, text, text_length, c): #(uttids, tgt_ids, tgt_labels, tgt_paddings, frames, src_paddings):\n",
    "#     print(fname)\n",
    "#     print(text)\n",
    "#     print(text_length)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([]), TensorShape([]), TensorShape([]))"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset.output_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"arg0:0\", shape=(), dtype=string)\n",
      "Tensor(\"arg1:0\", shape=(), dtype=string)\n",
      "Tensor(\"arg2:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# dataset = dataset.apply(\n",
    "#                         tf.data.experimental.bucket_by_sequence_length(\n",
    "#                         element_length_func=dataset_length_fn,\n",
    "#                         bucket_batch_sizes= [32, 32, 32, 32, 32, 32, 32, 32],\n",
    "#                         bucket_boundaries=[10, 20, 30, 40, 50, 60, 70],\n",
    "#                         pad_to_bucket_boundary = [False, True, False],\n",
    "#        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset.make_one_shot_iterator()\n",
    "file_name, text, length = iterator.get_next()\n",
    "decoded_text = tf.decode_raw(text, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7 40  4  7 33  4 28  0  9 21 16 24  4  8 40  4 38  4  0  8 24 13  8 24\n",
      " 18  8 24  8 32 52  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "[ 7 33 13 38  0  5 20  7  8 40  0  8 24 16 21 54  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "[ 8 20  8 40  3 38  4  8 38  2  0  8 33  2  3 28  8  9 20  8  8 25  7 24\n",
      "  0  2 28  4  1 28  0  8 40 18  8 38  4  0  1 24  8 22 52  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:    \n",
    "    for i in range(3):\n",
    "        a = sess.run(decoded_text)\n",
    "        print(a)\n",
    "\n",
    "# with tf.Session() as sess:    \n",
    "#     for i in range(3):\n",
    "#         a = sess.run(decoded_text, feed_dict={fnames_placeholder: fnames, \n",
    "#                                               texts_placeholder: texts, \n",
    "#                                               lengths_placeholder: text_lengths\n",
    "#                                           })\n",
    "#         print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram_wrap_up_(fname, length):\n",
    "    \n",
    "    fname = fname.decode()\n",
    "    npy_name = fname.split('/')[1].replace('wav', 'npy')\n",
    "    mel_path = os.path.join(hp.mels_dir, npy_name)\n",
    "    mag_path = os.path.join(hp.mags_dir, npy_name)\n",
    "    \n",
    "    #     if os.path.isfile(mel_path) and os.path.isfile(mag_path):\n",
    "    if False:\n",
    "\n",
    "        mag = np.load(mag_path)\n",
    "        mel = np.load(mel_path) \n",
    "\n",
    "    else :\n",
    "\n",
    "        fpath = os.path.join(hp.data_dir, fname)\n",
    "        wav, fs = librosa.core.load(fpath, mono=True)\n",
    "        nsc = np.int(fs * hp.nsc_sec)\n",
    "        nov = np.int(fs * hp.nov_sec)\n",
    "        mag_coef = np.mean(spectrogram(wav, nsc, nov, fs), axis=0)\n",
    "        mel = mel_spectrogram(wav, nsc, nov, fs)\n",
    "        mag = true_spectrogram(wav, nsc, nov)\n",
    "\n",
    "        active = np.where(mag_coef > hp.db_limit)[0]\n",
    "\n",
    "        first = active[0]\n",
    "        last = active[-1] + 1\n",
    "\n",
    "        if first - hp.offset >= 0:\n",
    "            first = first - hp.offset\n",
    "        else:\n",
    "                first = 0\n",
    "\n",
    "        if last + hp.offset < len(mag_coef):\n",
    "            last = last + hp.offset\n",
    "        else:\n",
    "            last = len(mag_coef)\n",
    "\n",
    "        mag = mag[:, first:last]\n",
    "        mel = mel[:, first:last]\n",
    "\n",
    "        mag = mag / hp.max_db\n",
    "        mel = mel / hp.max_db\n",
    "\n",
    "        # Do I really need \n",
    "        t = mel.shape[1]\n",
    "        num_paddings = hp.r - (t % hp.r) if t % hp.r != 0 else 0 # 0 for multiples\n",
    "\n",
    "        mel = np.pad(mel.T, [[0, num_paddings], [0, 0]], mode=\"minimum\")\n",
    "        mag = np.pad(mag.T, [[0, num_paddings], [0, 0]], mode=\"minimum\")\n",
    "\n",
    "        mel = mel.T\n",
    "        mag = mag.T\n",
    "\n",
    "        mel = mel.astype(np.float32)\n",
    "        mag = mag.astype(np.float32) # Default is float64, type crashes at the Attention Wrapper\n",
    "\n",
    "        print('{:d}:{:d}'.format(first, last))\n",
    "\n",
    "        np.save(mag_path, mag)\n",
    "        np.save(mel_path, mel)\n",
    "\n",
    "#     print(fname)\n",
    "#     plt.figure(figsize=(20, 4))\n",
    "#     plt.subplot(1, 3, 1)\n",
    "#     plt.imshow(mag, origin='lower')\n",
    "#     plt.colorbar()\n",
    "#     plt.subplot(1, 3, 2)\n",
    "#     plt.imshow(mel, origin='lower')\n",
    "#     plt.colorbar()\n",
    "#     plt.subplot(1, 3, 3)\n",
    "#     plt.plot(mag_coef)\n",
    "#     plt.show()\n",
    "\n",
    "    y = mel.T.reshape((-1, hp.n_mels*hp.r))\n",
    "    mel = (mel.T[hp.r - 1::hp.r, :]) # Reduce sample size by r\n",
    "    mag = mag.T\n",
    "    \n",
    "    return y, mel, mag, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(\n",
    "    lambda fname, text, lengths, c: tf.py_func(spectrogram_wrap_up_,\n",
    "                                [fname, lengths],\n",
    "                                [tf.float32, tf.float32, tf.float32, tf.int32]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: (<unknown>, <unknown>, <unknown>, <unknown>), types: (tf.float32, tf.float32, tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "batch_dataset = dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"arg0:0\", dtype=float32)\n",
      "Tensor(\"arg1:0\", dtype=float32)\n",
      "Tensor(\"arg2:0\", dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot iterate over a shape with unknown rank.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-270-1421996df2d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                         \u001b[0melement_length_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset_length_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                         \u001b[0mbucket_batch_sizes\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                         \u001b[0mbucket_boundaries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m#                         pad_to_bucket_boundary = [False, True, False]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                         ))\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, transformation_func)\u001b[0m\n\u001b[0;32m   1188\u001b[0m           \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \"\"\"\n\u001b[1;32m-> 1190\u001b[1;33m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformation_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"`transformation_func` must return a Dataset.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\grouping.py\u001b[0m in \u001b[0;36m_apply_fn\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m    232\u001b[0m       return dataset.apply(\n\u001b[0;32m    233\u001b[0m           group_by_window(element_to_bucket_id, batching_fn,\n\u001b[1;32m--> 234\u001b[1;33m                           window_size_func=window_size_fn))\n\u001b[0m\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_apply_fn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, transformation_func)\u001b[0m\n\u001b[0;32m   1188\u001b[0m           \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \"\"\"\n\u001b[1;32m-> 1190\u001b[1;33m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformation_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"`transformation_func` must return a Dataset.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\grouping.py\u001b[0m in \u001b[0;36m_apply_fn\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;34m\"\"\"Function from `Dataset` to `Dataset` that applies the transformation.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     return _GroupByWindowDataset(dataset, key_func, reduce_func,\n\u001b[1;32m--> 120\u001b[1;33m                                  window_size_func)\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0m_apply_fn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\grouping.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, key_func, reduce_func, window_size_func)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_key_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_reduce_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_window_size_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindow_size_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\grouping.py\u001b[0m in \u001b[0;36m_make_reduce_func\u001b[1;34m(self, reduce_func, input_dataset)\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[0minput_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnested_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m         \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnested_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m         experimental_nested_dataset_support=True)\n\u001b[0m\u001b[0;32m    455\u001b[0m     if not isinstance(\n\u001b[0;32m    456\u001b[0m         wrapped_func.output_classes, dataset_ops._NestedDatasetComponent):  # pylint: disable=protected-access\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, add_to_graph, experimental_nested_dataset_support)\u001b[0m\n\u001b[0;32m   1858\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_data_structured_function_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1859\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1860\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1861\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1862\u001b[0m       \u001b[1;31m# Use the private method that will execute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\u001b[0m in \u001b[0;36madd_to_graph\u001b[1;34m(self, g)\u001b[0m\n\u001b[0;32m    477\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m     \u001b[1;34m\"\"\"Adds this function into the graph g.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 479\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_definition_if_needed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Adds this function into 'g'.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\u001b[0m in \u001b[0;36m_create_definition_if_needed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[1;34m\"\"\"Creates the function definition if it's not created yet.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_definition_if_needed_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_create_definition_if_needed_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\u001b[0m in \u001b[0;36m_create_definition_if_needed_impl\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    342\u001b[0m     temp_graph = func_graph_from_py_func(\n\u001b[0;32m    343\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_arg_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_arg_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m         self._capture_by_value, self._caller_device)\n\u001b[0m\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extra_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextra_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(func, arg_names, arg_types, name, capture_by_value, device, colocation_stack, container, collections_ref, arg_shapes)\u001b[0m\n\u001b[0;32m    862\u001b[0m     \u001b[1;31m# Call func and gather the output tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 864\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m     \u001b[1;31m# There is no way of distinguishing between a function not returning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mtf_data_structured_function_wrapper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   1792\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1794\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1795\u001b[0m       \u001b[1;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1796\u001b[0m       \u001b[1;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\grouping.py\u001b[0m in \u001b[0;36mbatching_fn\u001b[1;34m(bucket_id, grouped_dataset)\u001b[0m\n\u001b[0;32m    226\u001b[0m       shapes = make_padded_shapes(\n\u001b[0;32m    227\u001b[0m           \u001b[0mpadded_shapes\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mgrouped_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m           none_filler=none_filler)\n\u001b[0m\u001b[0;32m    229\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrouped_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadded_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\grouping.py\u001b[0m in \u001b[0;36mmake_padded_shapes\u001b[1;34m(shapes, none_filler)\u001b[0m\n\u001b[0;32m    200\u001b[0m         shape = [\n\u001b[0;32m    201\u001b[0m             \u001b[0mnone_filler\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m         ]\n\u001b[0;32m    204\u001b[0m         \u001b[0mpadded\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    590\u001b[0m     \u001b[1;34m\"\"\"Returns `self.dims` if the rank is known, otherwise raises ValueError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 592\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot iterate over a shape with unknown rank.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    593\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot iterate over a shape with unknown rank."
     ]
    }
   ],
   "source": [
    "dataset = dataset.apply(\n",
    "                        tf.data.experimental.bucket_by_sequence_length(\n",
    "                        element_length_func=dataset_length_fn,\n",
    "                        bucket_batch_sizes= [32, 32, 32, 32, 32, 32, 32, 32],\n",
    "                        bucket_boundaries=[10, 20, 30, 40, 50, 60, 70],\n",
    "#                         pad_to_bucket_boundary = [False, True, False]\n",
    "                        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = batch_dataset.make_one_shot_iterator()\n",
    "y, mel, mag = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:43\n",
      "11:39\n",
      "14:83\n",
      "15:56\n",
      "7:57\n",
      "9:49\n",
      "11:70\n",
      "8:64\n",
      "11:42\n",
      "8:99\n",
      "22:79\n",
      "15:70\n",
      "12:59\n",
      "13:80\n",
      "11:44\n",
      "21:113\n",
      "18:76\n",
      "14:85\n",
      "14:90\n",
      "0:48\n",
      "11:56\n",
      "16:70\n",
      "4:52\n",
      "18:64\n",
      "2:51\n",
      "12:61\n",
      "2:49\n",
      "17:100\n",
      "17:75\n",
      "17:77\n",
      "20:61\n",
      "16:66\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot batch tensors with different shapes in component 0. First element had shape [7,400] and element 1 had shape [6,400].\n\t [[node IteratorGetNext_22 (defined at <ipython-input-248-c0f0f6c7f89b>:2)  = IteratorGetNext[output_shapes=[<unknown>, <unknown>, <unknown>], output_types=[DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_22)]]\n\nCaused by op 'IteratorGetNext_22', defined at:\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\asyncio\\base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\asyncio\\base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-248-c0f0f6c7f89b>\", line 2, in <module>\n    y, mel, mag = iterator.get_next()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 421, in get_next\n    name=name)), self._output_types,\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 2108, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot batch tensors with different shapes in component 0. First element had shape [7,400] and element 1 had shape [6,400].\n\t [[node IteratorGetNext_22 (defined at <ipython-input-248-c0f0f6c7f89b>:2)  = IteratorGetNext[output_shapes=[<unknown>, <unknown>, <unknown>], output_types=[DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_22)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Cannot batch tensors with different shapes in component 0. First element had shape [7,400] and element 1 had shape [6,400].\n\t [[{{node IteratorGetNext_22}} = IteratorGetNext[output_shapes=[<unknown>, <unknown>, <unknown>], output_types=[DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_22)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-249-d96c8b663d06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0my_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmel_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmag_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmag\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#         print(mel_)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Cannot batch tensors with different shapes in component 0. First element had shape [7,400] and element 1 had shape [6,400].\n\t [[node IteratorGetNext_22 (defined at <ipython-input-248-c0f0f6c7f89b>:2)  = IteratorGetNext[output_shapes=[<unknown>, <unknown>, <unknown>], output_types=[DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_22)]]\n\nCaused by op 'IteratorGetNext_22', defined at:\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\asyncio\\base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\asyncio\\base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-248-c0f0f6c7f89b>\", line 2, in <module>\n    y, mel, mag = iterator.get_next()\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 421, in get_next\n    name=name)), self._output_types,\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 2108, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"c:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot batch tensors with different shapes in component 0. First element had shape [7,400] and element 1 had shape [6,400].\n\t [[node IteratorGetNext_22 (defined at <ipython-input-248-c0f0f6c7f89b>:2)  = IteratorGetNext[output_shapes=[<unknown>, <unknown>, <unknown>], output_types=[DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_22)]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:    \n",
    "    for i in range(3):\n",
    "        y_, mel_, mag_ = sess.run([y, mel, mag])\n",
    "#       print(mel_)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(mel_.T, origin='lower')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(mag_.T, origin='lower')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected list for 'input' argument to 'PyFunc' Op, not <RepeatDataset shapes: ((), (), ()), types: (tf.string, tf.string, tf.int32)>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-236-b7198099890b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpy_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspectrogram_wrap_up_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\u001b[0m in \u001b[0;36mpy_func\u001b[1;34m(func, inp, Tout, stateful, name)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m   return _internal_py_func(\n\u001b[1;32m--> 457\u001b[1;33m       func=func, inp=inp, Tout=Tout, stateful=stateful, eager=False, name=name)\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\u001b[0m in \u001b[0;36m_internal_py_func\u001b[1;34m(func, inp, Tout, stateful, eager, is_grad_func, name)\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m       result = gen_script_ops.py_func(\n\u001b[1;32m--> 281\u001b[1;33m           input=inp, token=token, Tout=Tout, name=name)\n\u001b[0m\u001b[0;32m    282\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m       result = gen_script_ops.py_func_stateless(\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_script_ops.py\u001b[0m in \u001b[0;36mpy_func\u001b[1;34m(input, token, Tout, name)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[0mTout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Tout\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_t\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mTout\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m--> 132\u001b[1;33m         \"PyFunc\", input=input, token=token, Tout=Tout, name=name)\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\주환\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    424\u001b[0m             raise TypeError(\n\u001b[0;32m    425\u001b[0m                 \u001b[1;34m\"Expected list for '%s' argument to '%s' Op, not %s.\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m                 (input_name, op_type_name, values))\n\u001b[0m\u001b[0;32m    427\u001b[0m           \u001b[1;31m# In cases where we expect all elements of the list to have the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m           \u001b[1;31m# same dtype, try to cast non-Tensor elements to that type.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected list for 'input' argument to 'PyFunc' Op, not <RepeatDataset shapes: ((), (), ()), types: (tf.string, tf.string, tf.int32)>."
     ]
    }
   ],
   "source": [
    "y, mel, mag = tf.py_func(spectrogram_wrap_up_, [dataset], [tf.float32, tf.float32, tf.float32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'4/4_4155.wav'\n",
      "b'\\x08\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\r\\x00\\x00\\x00\\x19\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x1d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00%\\x00\\x00\\x00\\t\\x00\\x00\\x00(\\x00\\x00\\x00\\x0b\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\n\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\"\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x16\\x00\\x00\\x006\\x00\\x00\\x00'\n",
      "31\n",
      "b'3/3_4584.wav'\n",
      "b'\\x01\\x00\\x00\\x00&\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x0e\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x15\\x00\\x00\\x00\\x0e\\x00\\x00\\x00\\x1d\\x00\\x00\\x00\\x04\\x00\\x00\\x00&\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0e\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x02\\x00\\x00\\x00&\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0e\\x00\\x00\\x00(\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x03\\x00\\x00\\x00&\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x16\\x00\\x00\\x004\\x00\\x00\\x00'\n",
      "58\n",
      "b'4/4_1466.wav'\n",
      "b'\\x01\\x00\\x00\\x00&\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x08\\x00\\x00\\x00&\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\n\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\t\\x00\\x00\\x00(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x0e\\x00\\x00\\x00\\x15\\x00\\x00\\x00\\x12\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x08\\x00\\x00\\x00 \\x00\\x00\\x004\\x00\\x00\\x00'\n",
      "39\n",
      "b'2/2_0413.wav'\n",
      "b'\\x01\\x00\\x00\\x00&\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x02\\x00\\x00\\x00&\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x00\\x00\\x00(\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x0e\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x04\\x00\\x00\\x00&\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x01\\x00\\x00\\x00(\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00(\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x08\\x00\\x00\\x00&\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x02\\x00\\x00\\x00&\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00!\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x0e\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x00\\x00\\x00(\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x10\\x00\\x00\\x00\\x15\\x00\\x00\\x00\\x05\\x00\\x00\\x00!\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x19\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x12\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x14\\x00\\x00\\x004\\x00\\x00\\x00'\n",
      "77\n",
      "b'3/3_0575.wav'\n",
      "b'\\t\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x02\\x00\\x00\\x00&\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00!\\x00\\x00\\x00\\x04\\x00\\x00\\x00(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\t\\x00\\x00\\x00(\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\r\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\"\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x08\\x00\\x00\\x00&\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x02\\x00\\x00\\x00&\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\t\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x0e\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x0e\\x00\\x00\\x00\\x15\\x00\\x00\\x00\\x08\\x00\\x00\\x00 \\x00\\x00\\x004\\x00\\x00\\x00'\n",
      "50\n",
      "b'3/3_3440.wav'\n",
      "b'\\x01\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x1b\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\t\\x00\\x00\\x00(\\x00\\x00\\x00\\n\\x00\\x00\\x00!\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x08\\x00\\x00\\x00&\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\t\\x00\\x00\\x00!\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x02\\x00\\x00\\x00&\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\t\\x00\\x00\\x00\\x19\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06\\x00\\x00\\x00(\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x08\\x00\\x00\\x00&\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x03\\x00\\x00\\x00&\\x00\\x00\\x00\\x04\\x00\\x00\\x00(\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0e\\x00\\x00\\x00\\x15\\x00\\x00\\x00\\x08\\x00\\x00\\x00 \\x00\\x00\\x004\\x00\\x00\\x00'\n",
      "54\n",
      "b'4/4_3858.wav'\n",
      "b'\\t\\x00\\x00\\x00\\x19\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x12\\x00\\x00\\x00&\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x19\\x00\\x00\\x00\\x01\\x00\\x00\\x00(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x0c\\x00\\x00\\x00!\\x00\\x00\\x00\\x04\\x00\\x00\\x00&\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x0f\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x19\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x15\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x0e\\x00\\x00\\x00\\x08\\x00\\x00\\x00&\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x19\\x00\\x00\\x00\\x08\\x00\\x00\\x00 \\x00\\x00\\x004\\x00\\x00\\x00'\n",
      "40\n",
      "b'3/3_4029.wav'\n",
      "b'\\x08\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x02\\x00\\x00\\x00&\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x08\\x00\\x00\\x00&\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0f\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x12\\x00\\x00\\x00(\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x0c\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x14\\x00\\x00\\x004\\x00\\x00\\x00'\n",
      "31\n",
      "b'3/3_1867.wav'\n",
      "b'\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00!\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\t\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00!\\x00\\x00\\x00\\x07\\x00\\x00\\x00&\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x10\\x00\\x00\\x00&\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\t\\x00\\x00\\x00(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x04\\x00\\x00\\x00&\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x19\\x00\\x00\\x00\\x12\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x08\\x00\\x00\\x00 \\x00\\x00\\x004\\x00\\x00\\x00'\n",
      "39\n",
      "b'4/4_1161.wav'\n",
      "b'\\x02\\x00\\x00\\x00\\x15\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x08\\x00\\x00\\x00&\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\t\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00&\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\"\\x00\\x00\\x004\\x00\\x00\\x00'\n",
      "23\n",
      "b'1/1_0590.wav'\n",
      "b'\\x08\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x00\\x00\\x00(\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x08\\x00\\x00\\x00&\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x15\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0f\\x00\\x00\\x00&\\x00\\x00\\x00\\x02\\x00\\x00\\x00(\\x00\\x00\\x00\\x0f\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x03\\x00\\x00\\x00&\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\t\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x04\\x00\\x00\\x00(\\x00\\x00\\x00\\x04\\x00\\x00\\x00&\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x10\\x00\\x00\\x00&\\x00\\x00\\x00\\x01\\x00\\x00\\x00(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x00\\x00\\x00(\\x00\\x00\\x00\\t\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x0e\\x00\\x00\\x00\\x15\\x00\\x00\\x00\\x12\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x08\\x00\\x00\\x00 \\x00\\x00\\x004\\x00\\x00\\x00'\n",
      "67\n",
      "b'2/2_0182.wav'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x06\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00(\\x00\\x00\\x00\\r\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x12\\x00\\x00\\x00\\x02\\x00\\x00\\x00&\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x19\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00!\\x00\\x00\\x00\\x07\\x00\\x00\\x00&\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\n\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\t\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x1d\\x00\\x00\\x00\\x12\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x18\\x00\\x00\\x006\\x00\\x00\\x00'\n",
      "41\n",
      "b'4/4_1639.wav'\n",
      "b'\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\t\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x19\\x00\\x00\\x00\\x02\\x00\\x00\\x00&\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x1f\\x00\\x00\\x00\\x01\\x00\\x00\\x00!\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00&\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\t\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x14\\x00\\x00\\x00+\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x12\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x08\\x00\\x00\\x00 \\x00\\x00\\x004\\x00\\x00\\x00'\n",
      "48\n",
      "b'3/3_2293.wav'\n",
      "b'\\x08\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x15\\x00\\x00\\x00\\x02\\x00\\x00\\x00&\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\n\\x00\\x00\\x00(\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\t\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x19\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x12\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x08\\x00\\x00\\x00 \\x00\\x00\\x004\\x00\\x00\\x00'\n",
      "28\n",
      "b'4/4_3116.wav'\n",
      "b'\\x08\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x13\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x04\\x00\\x00\\x00(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\t\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x08\\x00\\x00\\x00&\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x08\\x00\\x00\\x00&\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\n\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\t\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x12\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x08\\x00\\x00\\x00 \\x00\\x00\\x004\\x00\\x00\\x00'\n",
      "52\n",
      "b'4/4_3771.wav'\n",
      "b'\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00!\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x1e\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\t\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0e\\x00\\x00\\x00\\x15\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\t\\x00\\x00\\x00!\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x15\\x00\\x00\\x006\\x00\\x00\\x00'\n",
      "28\n",
      "b'4/4_5282.wav'\n",
      "b\"\\x02\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00'\\x00\\x00\\x00\\x04\\x00\\x00\\x00%\\x00\\x00\\x00\\x02\\x00\\x00\\x00&\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\n\\x00\\x00\\x00&\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x19\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x12\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x08\\x00\\x00\\x00 \\x00\\x00\\x004\\x00\\x00\\x00\"\n",
      "33\n",
      "b'4/4_0874.wav'\n",
      "b'\\x03\\x00\\x00\\x00\\x15\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\t\\x00\\x00\\x00!\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\t\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x04\\x00\\x00\\x00(\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x1b\\x00\\x00\\x00\\x08\\x00\\x00\\x00 \\x00\\x00\\x004\\x00\\x00\\x00'\n",
      "35\n",
      "b'2/2_0262.wav'\n",
      "b'\\x01\\x00\\x00\\x00&\\x00\\x00\\x00\\x02\\x00\\x00\\x00&\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0e\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\n\\x00\\x00\\x00&\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00$\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x19\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x19\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x0c\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x04\\x00\\x00\\x00&\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\t\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x0e\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x19\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x15\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x12\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x12\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x14\\x00\\x00\\x004\\x00\\x00\\x00'\n",
      "58\n",
      "b'4/4_4602.wav'\n",
      "b'\\x07\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x0e\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x10\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x0e\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x19\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x1f\\x00\\x00\\x00\\x07\\x00\\x00\\x00(\\x00\\x00\\x00\\t\\x00\\x00\\x00 \\x00\\x00\\x006\\x00\\x00\\x00'\n",
      "24\n",
      "b'3/3_2425.wav'\n",
      "b'\\x08\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x00\\x00(\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\n\\x00\\x00\\x00\\x15\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00(\\x00\\x00\\x00\\x0c\\x00\\x00\\x00\\x08\\x00\\x00\\x00&\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x10\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\t\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x12\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x14\\x00\\x00\\x004\\x00\\x00\\x00'\n",
      "35\n",
      "b'3/3_3880.wav'\n",
      "b'\\x07\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x0f\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x15\\x00\\x00\\x00\\x01\\x00\\x00\\x00(\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x19\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x02\\x00\\x00\\x00&\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\n\\x00\\x00\\x00(\\x00\\x00\\x00\\x02\\x00\\x00\\x00&\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\t\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x04\\x00\\x00\\x00&\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x08\\x00\\x00\\x00\"\\x00\\x00\\x00\\x12\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x14\\x00\\x00\\x004\\x00\\x00\\x00'\n",
      "50\n",
      "b'4/4_1496.wav'\n",
      "b'\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x0c\\x00\\x00\\x00&\\x00\\x00\\x00\\x06\\x00\\x00\\x00!\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x08\\x00\\x00\\x00&\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00&\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x02\\x00\\x00\\x00(\\x00\\x00\\x00\\x01\\x00\\x00\\x00(\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x0e\\x00\\x00\\x00\\x15\\x00\\x00\\x00\\x08\\x00\\x00\\x00 \\x00\\x00\\x004\\x00\\x00\\x00'\n",
      "40\n",
      "b'4/4_1100.wav'\n",
      "b'\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00(\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x08\\x00\\x00\\x00&\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x05\\x00\\x00\\x00!\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x14\\x00\\x00\\x00+\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x08\\x00\\x00\\x00 \\x00\\x00\\x004\\x00\\x00\\x00'\n",
      "29\n",
      "b'3/3_4440.wav'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\t\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x02\\x00\\x00\\x00&\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0e\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x04\\x00\\x00\\x00!\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x19\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00!\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x08\\x00\\x00\\x00\"\\x00\\x00\\x00\\x04\\x00\\x00\\x00&\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0e\\x00\\x00\\x00\\x15\\x00\\x00\\x00\\x08\\x00\\x00\\x00 \\x00\\x00\\x004\\x00\\x00\\x00'\n",
      "33\n",
      "b'3/3_4235.wav'\n",
      "b'\\t\\x00\\x00\\x00(\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\t\\x00\\x00\\x00!\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x00\\x00\\x00(\\x00\\x00\\x00\\x08\\x00\\x00\\x00$\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x00\\x00\\x00(\\x00\\x00\\x00\\t\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x1f\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x15\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x04\\x00\\x00\\x00&\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x02\\x00\\x00\\x00&\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x0e\\x00\\x00\\x00\\x15\\x00\\x00\\x00\\x12\\x00\\x00\\x00\\x07\\x00\\x00\\x00&\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x02\\x00\\x00\\x00(\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x14\\x00\\x00\\x004\\x00\\x00\\x00'\n",
      "72\n",
      "b'1/1_0675.wav'\n",
      "b'\\x06\\x00\\x00\\x00(\\x00\\x00\\x00\\x0c\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x05\\x00\\x00\\x00(\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\t\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x19\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x04\\x00\\x00\\x00(\\x00\\x00\\x00\\x01\\x00\\x00\\x00(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x00\\x00\\x00$\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x14\\x00\\x00\\x004\\x00\\x00\\x00'\n",
      "40\n",
      "b'4/4_2292.wav'\n",
      "b\"\\x07\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\t\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x02\\x00\\x00\\x00(\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x08\\x00\\x00\\x00&\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\t\\x00\\x00\\x00(\\x00\\x00\\x00\\x01\\x00\\x00\\x00&\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0e\\x00\\x00\\x00\\x1f\\x00\\x00\\x00\\x08\\x00\\x00\\x00'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\t\\x00\\x00\\x00!\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00(\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x19\\x00\\x00\\x00\\x08\\x00\\x00\\x00 \\x00\\x00\\x004\\x00\\x00\\x00\"\n",
      "33\n",
      "b'4/4_3558.wav'\n",
      "b'\\x05\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x07\\x00\\x00\\x00&\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x02\\x00\\x00\\x00(\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x14\\x00\\x00\\x004\\x00\\x00\\x00'\n",
      "22\n",
      "b'4/4_1869.wav'\n",
      "b'\\x02\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x14\\x00\\x00\\x00,\\x00\\x00\\x00\\x08\\x00\\x00\\x00&\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x01\\x00\\x00\\x00(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\t\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x07\\x00\\x00\\x00(\\x00\\x00\\x00\\t\\x00\\x00\\x00\\x14\\x00\\x00\\x004\\x00\\x00\\x00'\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:    \n",
    "    for i in range(30):\n",
    "        a, b, c = sess.run([file_name, text, length], feed_dict={fnames_placeholder: fnames, \n",
    "                                              texts_placeholder: texts, \n",
    "                                              lengths_placeholder: text_lengths\n",
    "                                                                })\n",
    "        print(a)\n",
    "        print(b)\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "batch_dataset = dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset.make_one_shot_iterator()`\n",
    "file_name, text = iterator.get_next()\n",
    "text_decoded = tf.decode_raw(text, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, mel, mag = tf.py_func(spectrogram_wrap_up, [fname], [tf.float32, tf.float32, tf.float32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.experimental.bucket_by_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.experimental.bucket_by_sequence_length(\n",
    "    element_length_func,\n",
    "    bucket_boundaries,\n",
    "    bucket_batch_sizes,\n",
    "    padded_shapes=None,\n",
    "    pad_to_bucket_boundary=False,\n",
    "    no_padding=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterator = dataset.make_one_shot_iterator()\n",
    "# file_name, text = iterator.get_next()\n",
    "# text_decoded = tf.decode_raw(text, tf.int32)\n",
    "\n",
    "iterator = batch_dataset.make_one_shot_iterator()\n",
    "file_name, text = iterator.get_next()\n",
    "text_decoded = tf.decode_raw(text, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:    \n",
    "    for i in range(3):\n",
    "        f, t = sess.run([file_name, text])\n",
    "        print(f)\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:    \n",
    "    for i in range(3):\n",
    "        f, t = sess.run([file_name, text_decoded])\n",
    "        print(f)\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram(wav, nsc, nov, fs):\n",
    "    \n",
    "    \n",
    "    S = librosa.feature.melspectrogram(y=wav, sr=fs, n_fft=nsc, hop_length=nov, power=2.0)\n",
    "    dbS = 20 * np.log10(np.maximum(S, hp.eps))\n",
    "    \n",
    "    \n",
    "    return dbS\n",
    "\n",
    "def mel_spectrogram(wav, nsc, nov, fs):\n",
    "    \n",
    "    \n",
    "    S = librosa.feature.melspectrogram(y=wav, sr=fs, n_fft=nsc, hop_length=nov, power=2.0, n_mels = hp.n_mels)\n",
    "    dbS = 20 * np.log10(np.maximum(S, hp.eps))\n",
    "    \n",
    "    \n",
    "    return dbS\n",
    "\n",
    "def true_spectrogram(wav, nsc, nov):\n",
    "    \n",
    "    \n",
    "    S = librosa.core.stft(wav, n_fft=nsc, hop_length=nov)\n",
    "    Sxx = abs(S)\n",
    "    dbS = 20 * np.log10(np.maximum(Sxx, hp.eps))\n",
    "    \n",
    "    \n",
    "    return dbS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_decay(init_lr, global_step, warmup_steps=4000.):\n",
    "    '''Noam scheme from tensor2tensor'''\n",
    "    step = tf.cast(global_step + 1, dtype=tf.float32)\n",
    "    return init_lr * warmup_steps ** 0.5 * tf.minimum(step * warmup_steps ** -1.5, step ** -0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = file_name\n",
    "text = text_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram_wrap_up(fname):\n",
    "    \n",
    "    fname = fname.decode()\n",
    "    npy_name = fname.split('/')[1].replace('wav', 'npy')\n",
    "    mel_path = os.path.join(hp.mels_dir, npy_name)\n",
    "    mag_path = os.path.join(hp.mags_dir, npy_name)\n",
    "    \n",
    "    #     if os.path.isfile(mel_path) and os.path.isfile(mag_path):\n",
    "    if False:\n",
    "\n",
    "        mag = np.load(mag_path)\n",
    "        mel = np.load(mel_path) \n",
    "\n",
    "    else :\n",
    "\n",
    "        fpath = os.path.join(hp.data_dir, fname)\n",
    "        wav, fs = librosa.core.load(fpath, mono=True)\n",
    "        nsc = np.int(fs * hp.nsc_sec)\n",
    "        nov = np.int(fs * hp.nov_sec)\n",
    "        mag_coef = np.mean(spectrogram(wav, nsc, nov, fs), axis=0)\n",
    "        mel = mel_spectrogram(wav, nsc, nov, fs)\n",
    "        mag = true_spectrogram(wav, nsc, nov)\n",
    "\n",
    "        active = np.where(mag_coef > hp.db_limit)[0]\n",
    "\n",
    "        first = active[0]\n",
    "        last = active[-1] + 1\n",
    "\n",
    "        if first - hp.offset >= 0:\n",
    "            first = first - hp.offset\n",
    "        else:\n",
    "                first = 0\n",
    "\n",
    "        if last + hp.offset < len(mag_coef):\n",
    "            last = last + hp.offset\n",
    "        else:\n",
    "            last = len(mag_coef)\n",
    "\n",
    "        mag = mag[:, first:last]\n",
    "        mel = mel[:, first:last]\n",
    "\n",
    "        mag = mag / hp.max_db\n",
    "        mel = mel / hp.max_db\n",
    "\n",
    "        # Do I really need \n",
    "        t = mel.shape[1]\n",
    "        num_paddings = hp.r - (t % hp.r) if t % hp.r != 0 else 0 # 0 for multiples\n",
    "\n",
    "        mel = np.pad(mel.T, [[0, num_paddings], [0, 0]], mode=\"minimum\")\n",
    "        mag = np.pad(mag.T, [[0, num_paddings], [0, 0]], mode=\"minimum\")\n",
    "\n",
    "        mel = mel.T\n",
    "        mag = mag.T\n",
    "\n",
    "        mel = mel.astype(np.float32)\n",
    "        mag = mag.astype(np.float32) # Default is float64, type crashes at the Attention Wrapper\n",
    "\n",
    "        print('{:d}:{:d}'.format(first, last))\n",
    "\n",
    "        np.save(mag_path, mag)\n",
    "        np.save(mel_path, mel)\n",
    "\n",
    "#     print(fname)\n",
    "#     plt.figure(figsize=(20, 4))\n",
    "#     plt.subplot(1, 3, 1)\n",
    "#     plt.imshow(mag, origin='lower')\n",
    "#     plt.colorbar()\n",
    "#     plt.subplot(1, 3, 2)\n",
    "#     plt.imshow(mel, origin='lower')\n",
    "#     plt.colorbar()\n",
    "#     plt.subplot(1, 3, 3)\n",
    "#     plt.plot(mag_coef)\n",
    "#     plt.show()\n",
    "\n",
    "    y = mel.T.reshape((-1, hp.n_mels*hp.r))\n",
    "    mel = (mel.T[hp.r - 1::hp.r, :]) # Reduce sample size by r\n",
    "    mag = mag.T\n",
    "    \n",
    "    return y, mel, mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram_wrap_up_2(names):\n",
    "    \n",
    "    y = []\n",
    "    mel = []\n",
    "    mag = []\n",
    "    \n",
    "    for name in names:\n",
    "#       print(name)\n",
    "        y_, mel_, mag_ = spectrogram_wrap_up(name)\n",
    "        y.append(y_)\n",
    "        mel.append(mel_)\n",
    "        mag.append(mag_)\n",
    "        \n",
    "    y = np.asarray(y)\n",
    "    mel = np.asarray(mel)\n",
    "    mag = np.asarray(mag)\n",
    "    \n",
    "    return y, mel, mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y, mel, mag = tf.py_func(spectrogram_wrap_up, [fname], [tf.float32, tf.float32, tf.float32])\n",
    "y, mel, mag = tf.py_func(spectrogram_wrap_up_2, [fname], [tf.float32, tf.float32, tf.float32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:    \n",
    "    for i in range(3):\n",
    "        f = sess.run([fname])\n",
    "        print(f[0][0].decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:    \n",
    "    for i in range(3):\n",
    "        y_, mel_, mag_ = sess.run([y, mel, mag])\n",
    "        print(mel_)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(mel_[0].T, origin='lower')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(mag_[0].T, origin='lower')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = tf.concat((tf.zeros_like(mel[:1, :]), mel[:-1, :]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input.set_shape([None, hp.n_mels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"embedding\", reuse=tf.AUTO_REUSE):\n",
    "    lookup_table = tf.get_variable('lookup_table', \n",
    "                                   dtype=tf.float32, \n",
    "                                   shape=[len(hp.vocab), hp.embed_size],\n",
    "                                   initializer=tf.truncated_normal_initializer(mean=0.0, stddev=0.01))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_text = tf.nn.embedding_lookup(lookup_table, text_decoded)\n",
    "embed_text = tf.expand_dims(embed_text, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    x = sess.run(embed_text)\n",
    "    plt.imshow(x[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"prenet\", reuse=tf.AUTO_REUSE):\n",
    "    outputs = tf.layers.dense(embed_text, units=hp.num_prenet_node_1, activation=tf.nn.relu, name=\"dense1\")\n",
    "    outputs = tf.layers.dropout(outputs, rate=hp.dropout_rate, name=\"dropout1\")\n",
    "    outputs = tf.layers.dense(outputs, units=hp.num_prenet_node_2, activation=tf.nn.relu, name=\"dense2\")\n",
    "    outputs = tf.layers.dropout(outputs, rate=hp.dropout_rate, name=\"dropout2\") \n",
    "\n",
    "    prenet_result = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    x = sess.run(prenet_result)\n",
    "    plt.imshow(x[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"conv1d_banks\", reuse=tf.AUTO_REUSE):\n",
    "    for k in range(1, hp.K + 1):\n",
    "        with tf.variable_scope(\"filter_num_{}\".format(k)):\n",
    "            params = {\"inputs\":prenet_result, \"filters\":hp.num_k_filter, \"kernel_size\":k,\n",
    "                    \"dilation_rate\":1, \"padding\":\"SAME\", \"activation\":None, \n",
    "                    \"use_bias\":False, \"reuse\":tf.AUTO_REUSE}\n",
    "\n",
    "            # Works when resue = True\n",
    "            # For i loop, filter is reused.\n",
    "\n",
    "            conv_outputs = tf.layers.conv1d(**params)\n",
    "            if k == 1:\n",
    "                conv_bank_outputs = conv_outputs\n",
    "            else:\n",
    "                conv_bank_outputs = tf.concat((conv_bank_outputs, conv_outputs), axis=2)\n",
    "\n",
    "    conv_bank_result = conv_bank_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    x = sess.run(conv_bank_result)\n",
    "    plt.imshow(x[0, :, :], aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " max_pooling_result = tf.layers.max_pooling1d(conv_bank_result, pool_size=2, strides=1, padding=\"same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    x = sess.run(max_pooling_result)\n",
    "    plt.imshow(x[0, :, :], aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_bank_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"conv1d_1\"):       \n",
    "    params = {\"inputs\":max_pooling_result, \"filters\":hp.num_conv1d_proj_filter, \"kernel_size\":hp.size_conv1d_proj_filter,\n",
    "                    \"dilation_rate\":1, \"padding\":\"SAME\", \"activation\":None, \n",
    "                    \"use_bias\":False, \"reuse\":tf.AUTO_REUSE}\n",
    "    conv_proj_1_result = tf.layers.conv1d(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    x = sess.run(conv_proj_1_result)\n",
    "    plt.imshow(x[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"conv1d_1\"):\n",
    "    bn_1_result = tf.contrib.layers.batch_norm(inputs=conv_proj_1_result,\n",
    "                                           center=True,\n",
    "                                           scale=True,\n",
    "                                           updates_collections=None,\n",
    "                                           is_training=True,\n",
    "                                           scope=\"conv1d_1\",\n",
    "                                           fused=True,\n",
    "                                           reuse=tf.AUTO_REUSE)\n",
    "    batch_norm_1_result = tf.nn.relu(bn_1_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    x = sess.run(batch_norm_1_result)\n",
    "    plt.imshow(x[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"conv1d_2\"):\n",
    "    params = {\"inputs\":batch_norm_1_result, \"filters\":hp.num_conv1d_proj_filter, \"kernel_size\":hp.size_conv1d_proj_filter,\n",
    "                    \"dilation_rate\":1, \"padding\":\"SAME\", \"activation\":None, \n",
    "                    \"use_bias\":False, \"reuse\":tf.AUTO_REUSE}\n",
    "    conv_proj_2_result = tf.layers.conv1d(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    x = sess.run(conv_proj_2_result)\n",
    "    plt.imshow(x[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"conv1d_2\"):\n",
    "    bn_2_result = tf.contrib.layers.batch_norm(inputs=conv_proj_2_result,\n",
    "                                           center=True,\n",
    "                                           scale=True,\n",
    "                                           updates_collections=None,\n",
    "                                           is_training=True,\n",
    "                                           scope=\"conv1d_2\",\n",
    "                                           fused=True,\n",
    "                                           reuse=tf.AUTO_REUSE)\n",
    "    batch_norm_2_result = tf.nn.relu(bn_2_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    x = sess.run(batch_norm_2_result)\n",
    "    plt.imshow(x[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_output = prenet_result + batch_norm_2_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    x = sess.run(res_output)\n",
    "    plt.imshow(x[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highwaynet_output = []\n",
    "\n",
    "for i in range(hp.num_highwaynet_blocks):\n",
    "    scope = \"highwaynet_{:d}\".format(i)\n",
    "    with tf.variable_scope(scope):\n",
    "        \n",
    "        if i == 0:\n",
    "            highwaynet_input = res_output\n",
    "        else:\n",
    "            highwaynet_input = highwaynet_output\n",
    "\n",
    "        H = tf.layers.dense(highwaynet_input, units=hp.num_highwaynet_units, activation=tf.nn.relu, name=\"dense1\", reuse=tf.AUTO_REUSE)\n",
    "        T = tf.layers.dense(highwaynet_input, units=hp.num_highwaynet_units, activation=tf.nn.sigmoid,\n",
    "                            bias_initializer=tf.constant_initializer(-1.0), name=\"dense2\", reuse=tf.AUTO_REUSE)\n",
    "        highwaynet_output = H*T + highwaynet_input*(1.-T)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highwaynet_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    x = sess.run(highwaynet_output)\n",
    "    plt.imshow(x[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"gru\", reuse=tf.AUTO_REUSE):\n",
    "#     cell = tf.contrib.rnn.GRUCell(hp.num_gru_units)\n",
    "#     cell_bw = tf.contrib.rnn.GRUCell(hp.num_gru_units)\n",
    "    cell = tf.contrib.rnn.GRUCell(128)\n",
    "    cell_bw = tf.contrib.rnn.GRUCell(128)\n",
    "\n",
    "    output, _ = tf.nn.bidirectional_dynamic_rnn(cell, cell_bw, highwaynet_output, dtype=tf.float32)\n",
    "    gru_result = tf.concat(output, 2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"decoder_prenet\", reuse=tf.AUTO_REUSE):\n",
    "    outputs = tf.layers.dense(decoder_input, units=hp.num_prenet_node_1, activation=tf.nn.relu, name=\"dense1\")\n",
    "    outputs = tf.layers.dropout(outputs, rate=hp.dropout_rate, name=\"dropout1\")\n",
    "    outputs = tf.layers.dense(outputs, units=hp.num_prenet_node_2, activation=tf.nn.relu, name=\"dense2\")\n",
    "    decoder_prenet_result = tf.layers.dropout(outputs, rate=hp.dropout_rate, name=\"dropout2\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_prenet_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    x = sess.run(decoder_prenet_result)\n",
    "    plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_prenet_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_prenet_result_4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"attention_decoder\", reuse=tf.AUTO_REUSE):\n",
    "    \n",
    "    decoder_prenet_result_4D = tf.expand_dims(decoder_prenet_result, 0)\n",
    "\n",
    "    attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(hp.num_attention_units, gru_result)\n",
    "    decoder_cell = tf.contrib.rnn.GRUCell(hp.num_gru_units)\n",
    "    cell_with_attention = tf.contrib.seq2seq.AttentionWrapper(decoder_cell,\n",
    "                                                              attention_mechanism,\n",
    "                                                              hp.num_attention_units,\n",
    "                                                              alignment_history=True)\n",
    "    dec, state = tf.nn.dynamic_rnn(cell_with_attention, decoder_prenet_result_4D, dtype=tf.float32)\n",
    "#     dec, state = keras.layers.RNN(cell_with_attention, decoder_prenet_result_4D, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_prenet_result_4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    x = sess.run(state)\n",
    "    x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"attention_decoder\", reuse=tf.AUTO_REUSE):\n",
    "    \n",
    "    alignment = tf.transpose(state.alignment_history.stack(),[1,2,0])\n",
    "\n",
    "    with tf.variable_scope(\"decoder_gru_1\", reuse=tf.AUTO_REUSE):\n",
    "        cell = tf.contrib.rnn.GRUCell(128)\n",
    "        output, _ = tf.nn.dynamic_rnn(cell, dec, dtype=tf.float32)\n",
    "        gru_output_1 = tf.concat(output, 2)\n",
    "\n",
    "    dec = dec + gru_output_1\n",
    "\n",
    "    with tf.variable_scope(\"decoder_gru_2\", reuse=tf.AUTO_REUSE):\n",
    "        cell = tf.contrib.rnn.GRUCell(128)\n",
    "        output, _ = tf.nn.dynamic_rnn(cell, dec, dtype=tf.float32)\n",
    "        gru_output_2 = tf.concat(output, 2)\n",
    "\n",
    "    dec = dec + gru_output_2\n",
    "\n",
    "    # Outputs => (N, T_y/r, n_mels*r)\n",
    "    y_hat = tf.layers.dense(dec, hp.n_mels*hp.r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    x = sess.run(y_hat)\n",
    "    plt.imshow(x[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"decoder2\", reuse=tf.AUTO_REUSE):\n",
    "    dec_2_input = tf.reshape(y_hat, [1, -1, hp.n_mels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"decoder2\", reuse=tf.AUTO_REUSE):\n",
    "    with tf.variable_scope(\"conv1d_banks\", reuse=tf.AUTO_REUSE):\n",
    "        for k in range(1, hp.K + 1):\n",
    "            with tf.variable_scope(\"filter_num_{}\".format(k)):\n",
    "                params = {\"inputs\":dec_2_input, \"filters\":hp.num_k_filter, \"kernel_size\":k,\n",
    "                        \"dilation_rate\":1, \"padding\":\"SAME\", \"activation\":None, \n",
    "                        \"use_bias\":False, \"reuse\":tf.AUTO_REUSE}\n",
    "\n",
    "                # Works when resue = True\n",
    "                # For i loop, filter is reused.\n",
    "\n",
    "                conv_outputs = tf.layers.conv1d(**params)\n",
    "                if k == 1:\n",
    "                    conv_bank_outputs = conv_outputs\n",
    "                else:\n",
    "                    conv_bank_outputs = tf.concat((conv_bank_outputs, conv_outputs), axis=2)\n",
    "\n",
    "    dec_2_conv_bank_result = conv_bank_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"decoder2\", reuse=tf.AUTO_REUSE):\n",
    "    dec_2_max_pooling_result = tf.layers.max_pooling1d(dec_2_conv_bank_result, pool_size=2, strides=1, padding=\"same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"decoder2\", reuse=tf.AUTO_REUSE):\n",
    "    with tf.variable_scope(\"conv1d_1\"):\n",
    "        params = {\"inputs\":dec_2_max_pooling_result, \"filters\":hp.num_conv1d_proj_filter, \"kernel_size\":hp.size_conv1d_proj_filter,\n",
    "                        \"dilation_rate\":1, \"padding\":\"SAME\", \"activation\":None, \n",
    "                        \"use_bias\":False, \"reuse\":tf.AUTO_REUSE}\n",
    "\n",
    "        dec_2_conv_proj_1_result = tf.layers.conv1d(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"decoder2\", reuse=tf.AUTO_REUSE):\n",
    "    with tf.variable_scope(\"conv1d_1\"):\n",
    "        bn_1_result = tf.contrib.layers.batch_norm(inputs=dec_2_conv_proj_1_result,\n",
    "                                               center=True,\n",
    "                                               scale=True,\n",
    "                                               updates_collections=None,\n",
    "                                               is_training=True,\n",
    "                                               scope=\"conv1d_1\",\n",
    "                                               fused=True,\n",
    "                                               reuse=tf.AUTO_REUSE)\n",
    "        dec_2_batch_norm_1_result = tf.nn.relu(bn_1_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"decoder2\", reuse=tf.AUTO_REUSE):\n",
    "    with tf.variable_scope(\"conv1d_2\"):\n",
    "        params = {\"inputs\":dec_2_batch_norm_1_result, \"filters\":hp.num_conv1d_proj_filter, \"kernel_size\":hp.size_conv1d_proj_filter,\n",
    "                        \"dilation_rate\":1, \"padding\":\"SAME\", \"activation\":None, \n",
    "                        \"use_bias\":False, \"reuse\":tf.AUTO_REUSE}\n",
    "\n",
    "        dec_2_conv_proj_2_result = tf.layers.conv1d(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"decoder2\", reuse=tf.AUTO_REUSE):\n",
    "    with tf.variable_scope(\"conv1d_2\"):\n",
    "        bn_2_result = tf.contrib.layers.batch_norm(inputs=dec_2_conv_proj_2_result,\n",
    "                                               center=True,\n",
    "                                               scale=True,\n",
    "                                               updates_collections=None,\n",
    "                                               is_training=True,\n",
    "                                               scope=\"conv1d_2\",\n",
    "                                               fused=True,\n",
    "                                               reuse=tf.AUTO_REUSE)\n",
    "        dec_2_batch_norm_2_result = tf.nn.relu(bn_2_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"decoder2\", reuse=tf.AUTO_REUSE):\n",
    "    dec_2_sync_result = tf.layers.dense(dec_2_batch_norm_2_result, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"decoder2\", reuse=tf.AUTO_REUSE):\n",
    "    for i in range(hp.num_highwaynet_blocks):\n",
    "        scope = \"highwaynet_{:d}\".format(i)\n",
    "        with tf.variable_scope(scope):\n",
    "\n",
    "            if i == 0:\n",
    "                highwaynet_input = dec_2_sync_result\n",
    "            else:\n",
    "                highwaynet_input = highwaynet_output\n",
    "\n",
    "            highwaynet_output = []\n",
    "\n",
    "            H = tf.layers.dense(highwaynet_input, units=hp.num_highwaynet_units, activation=tf.nn.relu, name=\"dense1\", reuse=tf.AUTO_REUSE)\n",
    "            T = tf.layers.dense(highwaynet_input, units=hp.num_highwaynet_units, activation=tf.nn.sigmoid,\n",
    "                                bias_initializer=tf.constant_initializer(-1.0), name=\"dense2\", reuse=tf.AUTO_REUSE)\n",
    "            highwaynet_output = H*T + highwaynet_input*(1.-T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"dec_2_gru\", reuse=tf.AUTO_REUSE):\n",
    "    cell = tf.contrib.rnn.GRUCell(128)\n",
    "    cell_bw = tf.contrib.rnn.GRUCell(128)\n",
    "\n",
    "    output, _ = tf.nn.bidirectional_dynamic_rnn(cell, cell_bw, highwaynet_output, dtype=tf.float32)\n",
    "    dec_2_gru_result = tf.concat(output, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"decoder2\", reuse=tf.AUTO_REUSE):\n",
    "    with tf.variable_scope(\"final\", reuse=tf.AUTO_REUSE):\n",
    "        z_hat = tf.layers.dense(dec_2_gru_result, 1 + hp.nsc_sec*hp.fs//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 = tf.reduce_mean(tf.abs(y_hat - y))\n",
    "loss2 = tf.reduce_mean(tf.abs(z_hat - mag))\n",
    "loss = loss1 + loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    x = sess.run(loss)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "lr = learning_rate_decay(hp.lr, global_step=global_step)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=hp.lr)\n",
    "\n",
    "## gradient clipping\n",
    "gvs = optimizer.compute_gradients(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped = []\n",
    "\n",
    "for grad, var in gvs:\n",
    "    if grad is None:\n",
    "        clipped.append((grad, var))\n",
    "    else :\n",
    "        grad = tf.clip_by_norm(grad, 5.)\n",
    "        clipped.append((grad, var))\n",
    "    \n",
    "train_op = optimizer.apply_gradients(clipped, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'train'\n",
    "\n",
    "tf.summary.scalar('{}/loss1'.format(mode), loss1)\n",
    "tf.summary.scalar('{}/loss'.format(mode), loss)\n",
    "tf.summary.scalar('{}/lr'.format(mode), hp.lr)\n",
    "\n",
    "tf.summary.image(\"{}/mel_gt\".format(mode), tf.expand_dims(y, -1), max_outputs=1)\n",
    "tf.summary.image(\"{}/mel_hat\".format(mode), tf.expand_dims(y_hat, -1), max_outputs=1)\n",
    "tf.summary.image(\"{}/mag_gt\".format(mode), tf.expand_dims(mag, -1), max_outputs=1)\n",
    "tf.summary.image(\"{}/mag_hat\".format(mode), tf.expand_dims(z_hat, -1), max_outputs=1)\n",
    "\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    for i in range(100):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        _, gs = sess.run([train_op, global_step])\n",
    "        print(gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.logdir = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.train.MonitoredTrainingSession(summary_dir=hp.logdir, save_summaries_secs=60) as sess:\n",
    "    while 1:\n",
    "        for _ in tqdm(range(100), total=100, ncols=70, leave=False, unit='b'):\n",
    "            #_, gs = sess.run([train_op, global_step])\n",
    "            \n",
    "            _, gs = sess.run([dec_2_sync_result])\n",
    "\n",
    "            # Write checkpoint files\n",
    "            if gs % 1000 == 0:\n",
    "                sv.saver.save(sess, hp.logdir + '/model_gs_{}k'.format(gs//1000))\n",
    "\n",
    "                # plot the first alignment for logging\n",
    "                al = sess.run(alignment)\n",
    "                plt.imshow(al[0])\n",
    "                ply.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
